{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScitaPqhKtuW"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvztxQ6VsK2k"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYM61xrTsP5d"
   },
   "source": [
    "# TF Hub for TF2: Retraining an image classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1otmJgmbahf"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Image classification models have millions of parameters. Training them from\n",
    "scratch requires a lot of labeled training data and a lot of computing power. Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model.\n",
    "\n",
    "This Colab demonstrates how to build a Keras model for classifying five species of flowers by using a pre-trained TF2 SavedModel from TensorFlow Hub for image feature extraction, trained on the much larger and more general ImageNet dataset. Optionally, the feature extractor can be trained (\"fine-tuned\") alongside the newly added classifier.\n",
    "\n",
    "### Looking for a tool instead?\n",
    "\n",
    "This is a TensorFlow coding tutorial. If you want a tool that just builds the TensorFlow or TF Lite model for, take a look at the [make_image_classifier](https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier) command-line tool that gets [installed](https://www.tensorflow.org/hub/installation) by the PIP package `tensorflow-hub[make_image_classifier]`, or at [this](https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb) TF Lite colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bL54LWCHt5q5"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlauq-4FWGZM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.1.0\n",
      "Hub version: 0.8.0\n",
      "WARNING:tensorflow:From <ipython-input-2-0831fa394ed3>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmaHHH7Pvmth"
   },
   "source": [
    "## Select the TF2 SavedModel module to use\n",
    "\n",
    "For starters, use https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4. The same URL can be used in code to identify the SavedModel and in your browser to show its documentation. (Note that `hub.Modules` for TF 1.x won't work here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlsEcKVeuCnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4 with input size (224, 224)\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2_100_224\", 224) #@param [\"(\\\"mobilenet_v2_100_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
    "handle_base, pixels = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
    "\n",
    "BATCH_SIZE = 32 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTY8qzyYv3vl"
   },
   "source": [
    "## Set up the Flowers dataset\n",
    "\n",
    "Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBtFK1hO8KsO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umB5tswsfTEQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731 images belonging to 5 classes.\n",
      "Found 2939 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "                   interpolation=\"bilinear\")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
    "\n",
    "do_data_augmentation = False #@param {type:\"boolean\"}\n",
    "if do_data_augmentation:\n",
    "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      horizontal_flip=True,\n",
    "      width_shift_range=0.2, height_shift_range=0.2,\n",
    "      shear_range=0.2, zoom_range=0.2,\n",
    "      **datagen_kwargs)\n",
    "else:\n",
    "  train_datagen = valid_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FS_gVStowW3G"
   },
   "source": [
    "## Defining the model\n",
    "\n",
    "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
    "\n",
    "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaJW3XrPyFiF"
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50FYNIb1dmJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 6405      \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2e5WupIw2N2"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9f3yBUvkd_VJ"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_YKX2Qnfg6x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 91 steps, validate for 22 steps\n",
      "Epoch 1/5\n",
      "91/91 [==============================] - 19s 206ms/step - loss: 0.9558 - accuracy: 0.7423 - val_loss: 0.7369 - val_accuracy: 0.8480\n",
      "Epoch 2/5\n",
      "91/91 [==============================] - 15s 161ms/step - loss: 0.6959 - accuracy: 0.8786 - val_loss: 0.6921 - val_accuracy: 0.8636\n",
      "Epoch 3/5\n",
      "91/91 [==============================] - 14s 159ms/step - loss: 0.6570 - accuracy: 0.9013 - val_loss: 0.7240 - val_accuracy: 0.8551\n",
      "Epoch 4/5\n",
      "91/91 [==============================] - 14s 159ms/step - loss: 0.6280 - accuracy: 0.9192 - val_loss: 0.6771 - val_accuracy: 0.8807\n",
      "Epoch 5/5\n",
      "91/91 [==============================] - 15s 160ms/step - loss: 0.6053 - accuracy: 0.9274 - val_loss: 0.6768 - val_accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYOw0fTO1W4x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f534014d940>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCsAsQM1IRvA"
   },
   "source": [
    "Finally, the trained model can be saved for deployment to TF Serving or TF Lite (on mobile) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGvTi69oIc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/saved_flowers_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/saved_flowers_model/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = \"/tmp/saved_flowers_model\"\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzW4oNRjILaq"
   },
   "source": [
    "## Optional: Deployment to TensorFlow Lite\n",
    "\n",
    "[TensorFlow Lite](https://www.tensorflow.org/lite) lets you deploy TensorFlow models to mobile and IoT devices. The code below shows how to convert the trained model to TF Lite and apply post-training tools from the [TensorFlow Model Optimization Toolkit](https://www.tensorflow.org/model_optimization). Finally, it runs it in the TF Lite Interpreter to examine the resulting quality\n",
    "\n",
    "  * Converting without optimization provides the same results as before (up to roundoff error).\n",
    "  * Converting with optimization without any data quantizes the model weights to 8 bits, but inference still uses floating-point computation for the neural network activations. This reduces model size almost by a factor of 4 and improves CPU latency on mobile devices.\n",
    "  * On top, computation of the neural network activations can be quantized to 8-bit integers as well if a small reference dataset is provided to calibrate the quantization range. On a mobile device, this accelerates inference further and makes it possible to run on accelerators like EdgeTPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Va1Vo92fSyV6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote TFLite model of 8899916 bytes.\n"
     ]
    }
   ],
   "source": [
    "#@title Optimization settings\n",
    "optimize_lite_model = False  #@param {type:\"boolean\"}\n",
    "#@markdown Setting a value greater than zero enables quantization of neural network activations. A few dozen is already a useful amount.\n",
    "num_calibration_examples = 60  #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "representative_dataset = None\n",
    "if optimize_lite_model and num_calibration_examples:\n",
    "  # Use a bounded number of training examples without labels for calibration.\n",
    "  # TFLiteConverter expects a list of input tensors, each with batch size 1.\n",
    "  representative_dataset = lambda: itertools.islice(\n",
    "      ([image[None, ...]] for batch, _ in train_generator for image in batch),\n",
    "      num_calibration_examples)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "if optimize_lite_model:\n",
    "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "  if representative_dataset:  # This is optional, see above.\n",
    "    converter.representative_dataset = representative_dataset\n",
    "lite_model_content = converter.convert()\n",
    "\n",
    "with open(\"/tmp/lite_flowers_model\", \"wb\") as f:\n",
    "  f.write(lite_model_content)\n",
    "print(\"Wrote %sTFLite model of %d bytes.\" %\n",
    "      (\"optimized \" if optimize_lite_model else \"\", len(lite_model_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wqEmD0xIqeG"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=lite_model_content)\n",
    "# This little helper wraps the TF Lite interpreter as a numpy-to-numpy function.\n",
    "def lite_model(images):\n",
    "  interpreter.allocate_tensors()\n",
    "  interpreter.set_tensor(interpreter.get_input_details()[0]['index'], images)\n",
    "  interpreter.invoke()\n",
    "  return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMMK-fZrKrk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Lite model agrees with original model on 50 of 50 examples (100%).\n",
      "TF Lite model is accurate on 49 of 50 examples (98%).\n"
     ]
    }
   ],
   "source": [
    "#@markdown For rapid experimentation, start with a moderate number of examples.\n",
    "num_eval_examples = 50  #@param {type:\"slider\", min:0, max:700}\n",
    "eval_dataset = ((image, label)  # TFLite expects batch size 1.\n",
    "                for batch in train_generator\n",
    "                for (image, label) in zip(*batch))\n",
    "count = 0\n",
    "count_lite_tf_agree = 0\n",
    "count_lite_correct = 0\n",
    "for image, label in eval_dataset:\n",
    "  probs_lite = lite_model(image[None, ...])[0]\n",
    "  probs_tf = model(image[None, ...]).numpy()[0]\n",
    "  y_lite = np.argmax(probs_lite)\n",
    "  y_tf = np.argmax(probs_tf)\n",
    "  y_true = np.argmax(label)\n",
    "  count +=1\n",
    "  if y_lite == y_tf: count_lite_tf_agree += 1\n",
    "  if y_lite == y_true: count_lite_correct += 1\n",
    "  if count >= num_eval_examples: break\n",
    "print(\"TF Lite model agrees with original model on %d of %d examples (%g%%).\" %\n",
    "      (count_lite_tf_agree, count, 100.0 * count_lite_tf_agree / count))\n",
    "print(\"TF Lite model is accurate on %d of %d examples (%g%%).\" %\n",
    "      (count_lite_correct, count, 100.0 * count_lite_correct / count))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ScitaPqhKtuW"
   ],
   "name": "TF Hub for TF2: Retraining an image classifier",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
