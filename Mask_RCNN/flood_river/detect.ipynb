{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Path to trained weights file\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "DEFAULT_IMAGE_DIR = os.path.join(ROOT_DIR,'samples/flood_river/test_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TireConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"flood_river\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_splash(image, mask):\n",
    "    \"\"\"Apply color splash effect.\n",
    "    image: RGB image [height, width, 3]\n",
    "    mask: instance segmentation mask [height, width, instance count]\n",
    "\n",
    "    Returns result image.\n",
    "    \"\"\"\n",
    "    # Make a grayscale copy of the image. The grayscale copy still\n",
    "    # has 3 RGB channels, though.\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    \n",
    "    gray = np.zeros(image.shape)\n",
    "    # Copy color pixels from the original color image where mask is set\n",
    "    if mask.shape[-1] > 0:\n",
    "        # We're treating all instances as one, so collapse the mask into one layer\n",
    "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray.astype(np.uint8)\n",
    "    return splash\n",
    "\n",
    "def detect_and_color_splash(model, image_name=None, video_path=None):\n",
    "    assert image_name or video_path\n",
    "    image_path = os.path.join(DEFAULT_IMAGE_DIR, image_name)\n",
    "    \n",
    "    flood_depth_pythagoras  = []\n",
    "    flood_depth_hough  = []\n",
    "    # Image or video?\n",
    "    if image_path:\n",
    "        # Run model detection and generate the color splash effect\n",
    "        print(\"Running on {}\".format(image_path))\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=1)[0]\n",
    "        #J:check\n",
    "#         print('r', r)\n",
    "#         print('r[class_ids]', r['class_ids'])\n",
    "#         print('r[rois]', r['rois'])\n",
    "\n",
    "\n",
    "        # Color splash\n",
    "        splash = color_splash(image, r['masks'])\n",
    "        # Save output\n",
    "        file_name = image_name\n",
    "        cv2.imwrite('ans/'+file_name+'.jpg', splash)\n",
    "          \n",
    "#         imgray = cv2.cvtColor(splash.astype(np.uint8), cv2.COLOR_BGR2GRAY)     \n",
    "#         ret, thresh = cv2.threshold(imgray, 0, 255, 0)\n",
    "#         circles = cv2.HoughCircles(thresh,cv2.HOUGH_GRADIENT,1,100,param1=200,param2=10,minRadius=10,maxRadius=500)\n",
    "#         cv2.imwrite('mask.jpg',thresh)    \n",
    "\n",
    "       \n",
    "    elif video_path:\n",
    "        # Video capture\n",
    "        vcapture = cv2.VideoCapture(video_path)\n",
    "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Define codec and create video writer\n",
    "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
    "        vwriter = cv2.VideoWriter(file_name,\n",
    "                                  cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                                  fps, (width, height))\n",
    "\n",
    "        count = 0\n",
    "        success = True\n",
    "        while success:\n",
    "            print(\"frame: \", count)\n",
    "            # Read next image\n",
    "            success, image = vcapture.read()\n",
    "            if success:\n",
    "                # OpenCV returns images as BGR, convert to RGB\n",
    "                image = image[..., ::-1]\n",
    "                # Detect objects\n",
    "                r = model.detect([image], verbose=0)[0]\n",
    "                # Color splash\n",
    "                splash = color_splash(image, r['masks'])\n",
    "                # RGB -> BGR to save image to video\n",
    "                splash = splash[..., ::-1]\n",
    "                # Add image to video writer\n",
    "                vwriter.write(splash)\n",
    "                count += 1\n",
    "        vwriter.release()\n",
    "    print(\"Saved to \", file_name)\n",
    "    \n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note 2020-07-28\n",
    "\n",
    "/home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/logs/lood_river20200728T1333\n",
    "\n",
    "GPU_COUNT = 8\n",
    "IMAGES_PER_GPU = 1\n",
    "STEPS_PER_EPOCH = 100\n",
    "epochs=30\n",
    "real    61m9.886s\n",
    "user    435m52.298s\n",
    "sys     267m7.060s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "Re-starting from epoch 30\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    tire_weights_path = '/home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/logs/flood_river20200728T1333/mask_rcnn_flood_river_0030.h5'\n",
    "  \n",
    "    class InferenceConfig(TireConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "    tire_config = InferenceConfig()\n",
    "    #tire_config.display()\n",
    "    \n",
    "    # Create model\n",
    "    tire_model = modellib.MaskRCNN(mode=\"inference\", config=tire_config, model_dir='')\n",
    "       \n",
    "    # Load weights\n",
    "    tire_model.load_weights(tire_weights_path, by_name=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name = 1470009608395.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470009608395.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Saved to  1470009608395.jpg\n",
      "class_ids = [2 3 3 3 2 1 3 2 3 3 2]\n",
      "Image name = 1470020366229.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470020366229.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  148.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  1470020366229.jpg\n",
      "class_ids = [3 3 3 3 2 2 1 2 3 3]\n",
      "Image name = 1470011952548.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470011952548.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  1470011952548.jpg\n",
      "class_ids = [3 3 1 2 3 3 3 2 2 3 2]\n",
      "Image name = 1470297196228.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470297196228.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  147.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  1470297196228.jpg\n",
      "class_ids = [3 3 3 2 2 3 3 3 3 1 2 2]\n",
      "Image name = 1470286793440.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470286793440.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  148.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  1470286793440.jpg\n",
      "class_ids = [2 3 3 3 3 2 3 2 2 1 3 3]\n",
      "Image name = 1470026356158.jpg\n",
      "Running on /home/u3148947/twcc_gpfs/MaskRCNN/Mask_RCNN/samples/flood_river/test_img/1470026356158.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (576, 704, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  148.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  1470026356158.jpg\n",
      "class_ids = [3 2 3 3 2 3 2 3 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "#image_path = '1400720642688.jpg'\n",
    "\n",
    "# Train or evaluate\n",
    "for root, dirs, files in os.walk(DEFAULT_IMAGE_DIR):\n",
    "    for f in files:\n",
    "        print('Image name =', f)\n",
    "        tire_roi = detect_and_color_splash(tire_model, image_name=f)        \n",
    "        image_path1 = os.path.join(DEFAULT_IMAGE_DIR, f)    \n",
    "        img = cv2.imread(image_path1)\n",
    "        print('class_ids =', tire_roi['class_ids'])\n",
    "        masks = tire_roi['masks']\n",
    "        # Copy color pixels from the original color image where mask is set\n",
    "        gray = cv2.applyColorMap(img, 7)\n",
    "\n",
    "        alpha = 0.5\n",
    "        \n",
    "\n",
    "        for i in range(masks.shape[-1]):     \n",
    "            if tire_roi['class_ids'][i] == 1:   \n",
    "                color = [0,255,0]\n",
    "                for c in range(3):\n",
    "                    img[:, :, c] = np.where(masks[:,:,i] == 1, img[:, :, c] * (1 - alpha) + alpha * color[c], img[:, :, c])\n",
    "            if tire_roi['class_ids'][i] == 2:     \n",
    "                color = [230,255,102]\n",
    "                for c in range(3):\n",
    "                    img[:, :, c] = np.where(masks[:,:,i] == 1, img[:, :, c] * (1 - alpha) + alpha * color[c], img[:, :, c])\n",
    "            if tire_roi['class_ids'][i] == 3:     \n",
    "                color = [0,0,255]\n",
    "                for c in range(3):\n",
    "                    img[:, :, c] = np.where(masks[:,:,i] == 1, img[:, :, c] * (1 - alpha) + alpha * color[c], img[:, :, c])\n",
    "\n",
    "\n",
    "        cv2.imwrite('test_result/'+f,img)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
