{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2022-09-06]\n",
    "    1. just look inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 The TensorFlow Similarity Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Similarity Supervised Learning Visualization - Intermediate Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/similarity/blob/master/examples/supervised/supervised_visualization.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/similarity/blob/master/examples/supervised/supervised_visualization.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This intermeditate tutorial focuses on demonstrating Tensorflow Similarity's advanced training utilities and visualization capabilities. You will be training a similairty model that will learn how to group images of cats and dogs by training on a subset of the [Oxford-IIIT pet dataset](https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet) dataset. If you are not yet familiar Tensorflow Similarity, you might want to check out the [Hello World tutorial](https://github.com/tensorflow/similarity/blob/master/examples/supervised_hello_world.ipynb) to get familiar with the package.\n",
    "\n",
    "In this notebook you will learn how to use the:\n",
    "\n",
    "* `TFDatasetMultiShotMemorySampler()` to directly integrate with the Tensorflow dataset catalog. \n",
    "* `EfficientNetSim()` model architecture that leverage the [EficientNet](https://keras.io/api/applications/) backbone, data augmentation, and ImageNet pre-trained weights to have an efficient pre-trained model that we will fine-tune for similarity purposes.\n",
    "* `EvalCallback()` to track the matching classification perfomance during training.\n",
    "* `SplitValidationLoss()` callback to seperatly visualize how the performance of the seen and unseen classes evolves during training.\n",
    "* `projector()` to interactivaly explore the test example embedding space. This provides a sense of how well the model clusters similar looking images and which classes are entangled / confused.\n",
    "* `CircleLoss()`, which is a efficient hyper parameter sensitive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 回應 = 1 表示已啟用自動混合精度運算\n",
    "# 回應 = 0 表示已停止自動混合精度運算\n",
    "! export TF_ENABLE_AUTO_MIXED_PRECISION=1\n",
    "! export TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE=1\n",
    "! echo $TF_ENABLE_AUTO_MIXED_PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_ENABLE_AUTO_MIXED_PRECISION=0\n"
     ]
    }
   ],
   "source": [
    "#TF_ENABLE_AUTO_MIXED_PRECISION has no effect. 只是warning而已。關掉warning方法，在執行python程式上方多加一行\n",
    "%env TF_ENABLE_AUTO_MIXED_PRECISION=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# INFO messages are not printed.\n",
    "# This must be run before loading other modules.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install TF similarity if needed\n",
    "# try:\n",
    "#     import tensorflow_similarity as tfsim  # main package\n",
    "# except ModuleNotFoundError:\n",
    "#     !pip install tensorflow_similarity\n",
    "#     import tensorflow_similarity as tfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_similarity as tfsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已安裝了也同樣顯示上面訊息 sudo pip install --no-binary :all: nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfsim.utils.tf_cap_memory()  # Avoid GPU memory blow up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "In this first step, we are going to load the [Oxford-IIIT pet dataset](https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet) directly from the \n",
    "TensorFlow dataset catalog. This dataset has 37 classes representing different breeds of cats and dogs with roughly 200 images for each class. \n",
    "\n",
    "However, the dataset images are not of the same size, so we will need to resize them as part of the data loading. The `EfficientNetSim()` expects images to be 224x224 in the default configuration. However, because we use a random crop and resize layer as part of our augmentation strategy, it is important to have images that are slightly larger than the EfficientNet backbone's input size. Hence, we resize the images to 300 in the function below, which works well but you can experiment with different sizes as long as they are above 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300  # @param {type:\"integer\"}\n",
    "\n",
    "# preprocessing function that resizes images to ensure all images are the same shape\n",
    "def resize(img, label):\n",
    "    size = 300  # slightly larger than EfficienNetB0 size to allow random crops.\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        img = tf.cast(img, dtype=\"int32\") # **TODO** chnage to uint8 for fit the test image in kaggle..\n",
    "        img = tf.image.resize_with_pad(img, IMG_SIZE, IMG_SIZE)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFDatasetMultiShotMemorySampler\n",
    "\n",
    "The following cell loads data directly from the TensorFlow catalog using TensorFlow similarity\n",
    "`TFDatasetMultiShotMemorySampler()`. \n",
    "\n",
    "Using a sampler is required to ensure that each batch contains at least N samples of each classes incuded in each batch. Otherwise contrastive loss does not work properly as it can't compute positive distances.\n",
    "\n",
    "As a Similarity Models allows us to match data from unseen classes, you can experiment with the model's ability to generalize by only trainig on a subset of the classes. Feel free to experiment with the ratio of seen and unseed classes by changing the sampler parameters below. The more classes are seen during training the better it will perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然可以僅訓練子集並分類未訓練的新類，但訓練包含越多類別模型效能越佳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IDs seen during training [16, 6, 24, 15, 20, 27, 29, 2, 19, 9, 31, 8, 18, 35, 1, 34]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d052bc42f94ef8961ed1c9aab1def2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "converting train:   0%|          | 0/3680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 21:27:04.190524: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1850] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c975ffa59f443da5fb4695533ea8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing data:   0%|          | 0/3680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The initial batch size is 64 (16 classes * 4 examples per class) with 0 augmenters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c770418bac4356bb893e7a43aa5e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "filtering examples:   0%|          | 0/3680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20434711f46e496890f3c904acc7204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "selecting classes:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ec9ba60ab4a04b7f56de5e6660d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gather examples:   0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30775e21c1af402697271bfbbf17534f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indexing classes:   0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230447187bbe4cbcb27fa46136319227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "converting test:   0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bcd3dfb04b4e1898ec148f1fb70093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing data:   0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The initial batch size is 32 (16 classes * 2 examples per class) with 0 augmenters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71789b2a2bb2486185840bfbee66c266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "filtering examples:   0%|          | 0/3669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1250466e3f4d10a54f1a144c6cf4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "selecting classes:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcbfa52c51f4d05864a9bc89bb82655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gather examples:   0%|          | 0/740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7f0ff489e84e759349cba353e56714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indexing classes:   0%|          | 0/740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#子類別數量\n",
    "training_classes = 16  # @param {type:\"slider\", min:1, max:37}\n",
    "#每批中同一類的數量\n",
    "examples_per_class_per_batch = 4  # @param {type:\"integer\"}\n",
    "#隨機選取某數量的子類\n",
    "train_cls = random.sample(range(37), k=training_classes)\n",
    "#每批涵蓋的類別數，預設用全部子類\n",
    "classes_per_batch = max(16, training_classes)\n",
    "#符合efnet B0的輸入大小\n",
    "target_img_size = 224  # Size of B0 image input\n",
    "\n",
    "print(f\"Class IDs seen during training {train_cls}\")\n",
    "\n",
    "def img_augmentation(img_batch, y, *args):\n",
    "    # random resize and crop. Increase the size before we crop.\n",
    "    img_batch = tf.keras.layers.RandomCrop(target_img_size, target_img_size)(img_batch)\n",
    "    # random horizontal flip\n",
    "    img_batch = tf.image.random_flip_left_right(img_batch)\n",
    "    return img_batch, y\n",
    "\n",
    "\n",
    "# use the train split for training\n",
    "train_ds = tfsim.samplers.TFDatasetMultiShotMemorySampler(\n",
    "    \"oxford_iiit_pet\",\n",
    "    splits=\"train\",\n",
    "    examples_per_class_per_batch=examples_per_class_per_batch,\n",
    "    classes_per_batch=classes_per_batch,\n",
    "    preprocess_fn=resize,\n",
    "    class_list=train_cls,\n",
    "    augmenter=img_augmentation,\n",
    ")  # We filter train data to only keep the train classes.\n",
    "\n",
    "# use the test split for indexing and querying\n",
    "test_ds = tfsim.samplers.TFDatasetMultiShotMemorySampler(\n",
    "    \"oxford_iiit_pet\",\n",
    "    splits=\"test\",\n",
    "    total_examples_per_class=20,\n",
    "    classes_per_batch=classes_per_batch,\n",
    "    preprocess_fn=resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Class IDs seen during training [12, 19, 10, 35, 3, 24, 20, 9, 17, 2, 4, 8, 16, 18, 7, 25]\n",
    "    2022-09-06 10:30:44.170037: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n",
    "    Downloading and preparing dataset 773.52 MiB (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to     ~/tensorflow_datasets/oxford_iiit_pet/3.2.0...\n",
    "    Dl Completed...: 0 url [00:00, ? url/s]\n",
    "    Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
    "    Extraction completed...: 0 file [00:00, ? file/s]   要等待一陣子讓他連接 他會存在lab的當下資料夾下 tfsim_embedding/~/tensorflow_datasets/oxford_iiit_pet/3.2.0 而不是真正的家目錄下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## class mapping\n",
    "\n",
    "The following dictionaries map the class ids to the breed's name and the species type (Cat or Dog). These are used later on by the interactive projector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = {\n",
    "    0: \"Abyssinian\",\n",
    "    1: \"American bulldog\",\n",
    "    2: \"American pit bull terrier\",\n",
    "    3: \"Basset hound\",\n",
    "    4: \"Beagle\",\n",
    "    5: \"Bengal\",\n",
    "    6: \"Birman\",\n",
    "    7: \"Bombay\",\n",
    "    8: \"Boxer\",\n",
    "    9: \"British shorthair\",\n",
    "    10: \"Chihuahua\",\n",
    "    11: \"Egyptian mau\",\n",
    "    12: \"English cocker spaniel\",\n",
    "    13: \"English setter\",\n",
    "    14: \"German shorthaired\",\n",
    "    15: \"Great pyrenees\",\n",
    "    16: \"Havanese\",\n",
    "    17: \"Japanese chin\",\n",
    "    18: \"Keeshond\",\n",
    "    19: \"Leonberger\",\n",
    "    20: \"Maine coon\",\n",
    "    21: \"Miniature pinscher\",\n",
    "    22: \"Newfoundland\",\n",
    "    23: \"Persian\",\n",
    "    24: \"Pomeranian\",\n",
    "    25: \"Pug\",\n",
    "    26: \"Ragdoll\",\n",
    "    27: \"Russian blue\",\n",
    "    28: \"Saint bernard\",\n",
    "    29: \"Samoyed\",\n",
    "    30: \"Scottish terrier\",\n",
    "    31: \"Shiba inu\",\n",
    "    32: \"Siamese\",\n",
    "    33: \"Sphynx\",\n",
    "    34: \"Staffordshire bull terrier\",\n",
    "    35: \"Wheaten terrier\",\n",
    "    36: \"Yorkshire terrier\",\n",
    "}\n",
    "species = {\n",
    "    0: \"Dog\",\n",
    "    1: \"Cat\",\n",
    "    2: \"Cat\",\n",
    "    3: \"Cat\",\n",
    "    4: \"Cat\",\n",
    "    5: \"Dog\",\n",
    "    6: \"Dog\",\n",
    "    7: \"Dog\",\n",
    "    8: \"Cat\",\n",
    "    9: \"Dog\",\n",
    "    10: \"Cat\",\n",
    "    11: \"Dog\",\n",
    "    12: \"Cat\",\n",
    "    13: \"Cat\",\n",
    "    14: \"Cat\",\n",
    "    15: \"Cat\",\n",
    "    16: \"Cat\",\n",
    "    17: \"Cat\",\n",
    "    18: \"Cat\",\n",
    "    19: \"Cat\",\n",
    "    20: \"Dog\",\n",
    "    21: \"Cat\",\n",
    "    22: \"Cat\",\n",
    "    23: \"Dog\",\n",
    "    24: \"Cat\",\n",
    "    25: \"Cat\",\n",
    "    26: \"Dog\",\n",
    "    27: \"Dog\",\n",
    "    28: \"Cat\",\n",
    "    29: \"Cat\",\n",
    "    30: \"Cat\",\n",
    "    31: \"Cat\",\n",
    "    32: \"Dog\",\n",
    "    33: \"Dog\",\n",
    "    34: \"Cat\",\n",
    "    35: \"Cat\",\n",
    "    36: \"Cat\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Most metrics used to evaluate similarity models cannot be computed without indexing embeddings and performing query matching classification. TensorFlow Similarity provides callbacks that makes it easy to compute these performance metrics during training. \n",
    "\n",
    "These callbacks work by taking two disjoint sets of examples:\n",
    "1. A set of target examples and labels to be indexed. These will be examples returned by the search.\n",
    "2. A set of query examples and labels that will be search query. \n",
    "\n",
    "Then all metrics metrics are compute be analyzing how many correct matches are returned by the search. While very very fast, this process is still too slow to be done for every training step. Instead the evaluation is only computed `on_epoch_end()`.\n",
    "\n",
    "Additionally, the `EvalCallback()` and `SplitValidationLoss()` are TensorBoard aware - just add a `tf_logdir` path as illustrated below to have your metric logged. **WARNING** Tensorboard logging requires using a `TensorBoard()` callback that uses the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "    * 修改sim模型的metric_embedding_3 層的lauer name為\"embedding_norm\"，可訓練不可存檔\n",
    "    * 訓練完sim模型後，在改名\"embedding_norm\"存檔？原始的metric_embedd名稱作祟，無法存檔！\n",
    "    \n",
    "    * 建立sim模型時，追加top layer為keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm') 訓練時會無法rreset_index而中止\n",
    "    \n",
    "    * 修改sim模型的metric_embedding_3 層的lauer name為\"embedding_norm\"，可訓練 使用saved_model.save 可saved_model.load讀檔與辨識 OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = 200  # @param {type:\"integer\"}\n",
    "num_queries = 300  # @param {type:\"integer\"}\n",
    "k = 3  # @param {type:\"integer\"}\n",
    "log_dir = \"logs/%d/\" % (time())\n",
    "\n",
    "# Setup EvalCallback by splitting the test data into targets and queries.\n",
    "queries_x, queries_y = test_ds.get_slice(0, num_queries)\n",
    "targets_x, targets_y = test_ds.get_slice(num_queries, num_targets)\n",
    "tsc = tfsim.callbacks.EvalCallback(\n",
    "    queries_x,\n",
    "    queries_y,\n",
    "    targets_x,\n",
    "    targets_y,\n",
    "    metrics=[\"f1\"],\n",
    "    k=k,\n",
    "    # tb_logdir=log_dir  # uncomment if you want to track in tensorboard\n",
    ")\n",
    "\n",
    "# Setup an EvalCallback for a known and unknown class split.\n",
    "val_loss = tfsim.callbacks.EvalCallback(\n",
    "    queries_x,\n",
    "    queries_y,\n",
    "    targets_x,\n",
    "    targets_y,\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    known_classes=tf.constant(train_cls),\n",
    "    k=k,\n",
    "    # tb_logdir=log_dir  # uncomment if you want to track in tensorboard\n",
    ")\n",
    "\n",
    "# Adding the Tensorboard callback to track metrics in tensorboard.\n",
    "# tbc = tf.keras.callbacks.TensorBoard(log_dir=log_dir) # uncomment if you want to track in tensorboard\n",
    "\n",
    "callbacks = [\n",
    "    val_loss,\n",
    "    tsc,\n",
    "    # tbc # uncomment if you want to track in tensorboard\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "We are now going to fine-tune an `EfficientNetSim()` model using `CircleLoss()` function. Because we are fine tuning the model we don't need a lot of epochs. In particular, because the dataset is very small. The small dataset size also means the model will not generalize very well, and the callback metric values will not look impressive. However, this is why visual inspection is important, in practice the matching looks really good and the model is good enough.\n",
    "\n",
    "To improve performance, you can experiment with:\n",
    "* change the `embedding_size`.\n",
    "* set the `EfficientNetSim()` `trainable` parameters to 'partial' or 'full' to unfreeze some or all of the backbone layers.\n",
    "* changing the loss function to `MultiSimilarityLoss()`, `TripletLoss()`, or any other supported loss.\n",
    "* tweaking the learning rate.\n",
    "* tweaking the gamma parameter in the `CircleLoss()`.\n",
    "\n",
    "Additionally, you can also experiment with replacing the `EfficientNetSim()` with the architecture of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.example_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64 #128  # @param {type:\"integer\"}\n",
    "\n",
    "# building model\n",
    "model = tfsim.architectures.EfficientNetSim( # EfficientNet\n",
    "# base_model = tfsim.architectures.EfficientNetSim( # EfficientNet\n",
    "    train_ds.example_shape, # Must match size of EfficientNet version you use\n",
    "    embedding_size, # Size of the output embedding\n",
    "    #variant=\"B0\", # Which Variant of the EfficientNet to use. Defaults to \"B0\".\n",
    "    #trainable=, #\"full\" to make the entire backbone trainable, - \"partial\" to only make the last 3 block trainable - \"frozen\" to make it not trainable.\n",
    "    #l2_norm=,\n",
    "    pooling=\"gem\",    # Can change to use `gem` -> GeneralizedMeanPooling2D\n",
    "    gem_p=3.0,        # Increase the contrast between activations in the feature map.\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# inputs = base_model.input\n",
    "# output = base_model.output\n",
    "# output = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm')(output)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[inputs], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "efficientnetb0\n",
      "gem_pool\n",
      "embedding_norm\n"
     ]
    }
   ],
   "source": [
    "# set the last lalyer name \n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer._name)\n",
    "    #layer._name = layer.name + str(\"_2\")\n",
    "\n",
    "model.layers[-1]._name = \"embedding_norm\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"similarity_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "gem_pool (GeneralizedMeanPoo (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "embedding_norm (MetricEmbedd (None, 64)                81984     \n",
      "=================================================================\n",
      "Total params: 4,131,555\n",
      "Trainable params: 81,984\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance metric automatically set to cosine use the distance arg to override.\n",
      "100/100 [==============================] - 21s 144ms/step - loss: 48.5660 - val_loss: 50.2905\n",
      "binary_accuracy_known_classes: 0.7857 - binary_accuracy_unknown_classes: 0.7414\n",
      "f1: 0.8636\n"
     ]
    }
   ],
   "source": [
    "epochs = 1  # @param {type:\"integer\"}\n",
    "LR = 0.0001  # @param {type:\"number\"}\n",
    "gamma = 256  # @param {type:\"integer\"} # Loss hyper-parameter. 256 works well here.\n",
    "steps_per_epoch = 100\n",
    "val_steps = 50\n",
    "\n",
    "\n",
    "# init similarity loss\n",
    "loss = tfsim.losses.CircleLoss(gamma=gamma)\n",
    "\n",
    "# compiling and training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LR), loss=loss)\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f42547b5670>,\n",
       " <keras.engine.functional.Functional at 0x7f4254362fd0>,\n",
       " <tensorflow_similarity.layers.GeneralizedMeanPooling2D at 0x7f4284267ee0>,\n",
       " <tensorflow_similarity.layers.MetricEmbedding at 0x7f4254443fa0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "efficientnetb0\n",
      "gem_pool\n",
      "embedding_norm\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer._name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SaveModel\n",
    "    let's copy from somehwere out there.\n",
    "    \n",
    "    [todo] output = tf.keras.layers.Dense(64, name='embedding')(output)\n",
    "            output = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm')(output)\n",
    "            should we add this l2_nor in Top -layer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "efficientnetb0\n",
      "gem_pool\n",
      "embedding_norm\n",
      "input_4\n",
      "efficientnetb0\n",
      "gem_pool\n",
      "embedding_norm\n"
     ]
    }
   ],
   "source": [
    "# set the last lalyer name \n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer._name)\n",
    "    #layer._name = layer.name + str(\"_2\")\n",
    "\n",
    "model.layers[-1]._name = \"embedding_norm\"\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer._name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfsim-efnet-b0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfsim-efnet-b0/assets\n"
     ]
    }
   ],
   "source": [
    "model_save_dir = 'tfsim-efnet-b0/'\n",
    "\n",
    "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost',\n",
    "    #namespace_whitelist=None, save_debug_info=False, function_aliases=None,\n",
    "    #experimental_io_device=None, experimental_variable_policy=None,\n",
    "    #experimental_custom_gradients=True\n",
    ")\n",
    "\n",
    "\n",
    "# embedding_norm_model = tf.keras.Sequential(\n",
    "#     model,\n",
    "#     tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm')\n",
    "# )\n",
    "# embedding_norm_model.save(\n",
    "#     model_save_dir, \n",
    "#     options=save_options, \n",
    "#     include_optimizer=False\n",
    "# )\n",
    "\n",
    "\n",
    "tf.saved_model.save(model, model_save_dir, options=save_options)\n",
    "\n",
    "# model.save(\n",
    "#     model_save_dir, \n",
    "#     options=save_options, \n",
    "#     include_optimizer=False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1057510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1019672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1020864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1021049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1021371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1047745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1019454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1055823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1057027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1020615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1056240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1021025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1055453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1019840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1019986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1019018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1020106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1019171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1057764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1020550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1049596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1019921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1020888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1029783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1020308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1021412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1056560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1019799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1019485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1058156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1055014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1058573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1057883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1057949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1019526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1054525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1019631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1055334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1019212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1058319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1019358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1021090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1054271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1059153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1020783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1056657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1054205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1058670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1056306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1020413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1054917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1053443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1020742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1058736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1057093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1053509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1020082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1020454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1020147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1020267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1019317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1053835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1019945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1053346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1056930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1053716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1058990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1057347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1021251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1056723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1055889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1059407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1054108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1020574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1056143) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1019293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1058253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1053901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1019059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1033580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1020389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1059570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1055519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1019140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1055080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1020243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1021493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_similarity_model_1_layer_call_and_return_conditional_losses_1041639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1051312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1018994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1019768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1055726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1021210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1054644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1059087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1020929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1054710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1059504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1021186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1011319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1021347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1019607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1057444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_similarity_model_1_layer_call_and_return_conditional_losses_1043521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1053163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1059777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1020711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "#Reload Model and Check\n",
    "load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "\n",
    "loaded_model = tf.saved_model.load(\n",
    "    model_save_dir, \n",
    "    #options=load_locally,\n",
    ")\n",
    "\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "#     model_save_dir, \n",
    "#     options=load_locally,\n",
    "#     compile=False\n",
    "# ) \n",
    "\n",
    "# loaded_model.summary()\n",
    "\n",
    "embedding_fn = loaded_model.signatures[\"serving_default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'> dict_keys(['metric_embedding_1'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.11287818, -0.10832503, -0.13796909, -0.03698735,  0.19754942,\n",
       "        -0.05470496, -0.04839032,  0.04517763,  0.0206751 , -0.00838856,\n",
       "        -0.14765662, -0.1113561 , -0.14909455,  0.06483404,  0.1168419 ,\n",
       "         0.2262413 , -0.05476293, -0.08007982,  0.10172811, -0.26772088,\n",
       "        -0.05191431,  0.06654051,  0.22994415, -0.02983509, -0.15514494,\n",
       "         0.03623642,  0.04111739, -0.1330535 ,  0.08591234,  0.02032786,\n",
       "        -0.12149359,  0.02411855,  0.1198781 ,  0.1280244 ,  0.18334332,\n",
       "        -0.21422732, -0.05180394,  0.12627457,  0.03409532,  0.05326991,\n",
       "        -0.07292303, -0.06666929,  0.12273896, -0.05778563,  0.10370904,\n",
       "        -0.00138885,  0.16439037,  0.04329295, -0.01539031, -0.03171251,\n",
       "         0.0512972 , -0.02723633,  0.01199827, -0.04614533, -0.21564917,\n",
       "        -0.04500039,  0.3992623 , -0.10061475,  0.0315835 ,  0.00495048,\n",
       "        -0.16167009,  0.06921558, -0.06107598, -0.31805715]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = tf.keras.utils.get_file(\n",
    "    \"african_elephant.jpg\", \"https://i.imgur.com/Bvro0YD.png\"\n",
    ")\n",
    "image_tensor = tf.convert_to_tensor(\n",
    "        np.array(Image.open(image_path).convert(\"RGB\")).astype(np.float32)\n",
    "    )\n",
    "expanded_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "embedding = embedding_fn(expanded_tensor)\n",
    "\n",
    "print(expanded_tensor.dtype, embedding.keys())\n",
    "embedding['metric_embedding_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if add tf.math.l2_normalize [TODO]\n",
    "    savedModel 有問題\n",
    "    後續嘗試save best model as h5 as keras model formate, then load the best model (h5) back and add input layer, l2_nor layer after 64D. 最後組好才savedModel to dir then zip to submission.zip.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if add tf.math.l2_normalize [TODO]\n",
    "\n",
    "# load_options = tf.saved_model.LoadOptions(\n",
    "#     allow_partial_checkpoint=False, experimental_io_device=None,\n",
    "#     experimental_skip_checkpoint=False\n",
    "# )\n",
    "\n",
    "\n",
    "# awesome_model = tf.keras.Sequential(\n",
    "#     tf.saved_model.load(model_save_dir),# options=load_options),\n",
    "#     tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm')\n",
    "# )\n",
    "\n",
    "# awesome_model = tf.saved_model.load(model_save_dir)\n",
    "# awesome_model.summary()# just skip for summary bug, So basically saved_model.load makes summary not work anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_norm_model = tf.keras.Sequential(\n",
    "#     model,\n",
    "#     tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='embedding_norm')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfsim-efnet-b0/ ['assets', 'variables'] ['saved_model.pb']\n",
      "tfsim-efnet-b0/assets [] []\n",
      "tfsim-efnet-b0/variables [] ['variables.index', 'variables.data-00000-of-00001']\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "from os.path import basename\n",
    "\n",
    "dirName = model_save_dir\n",
    "\n",
    "with ZipFile('submission.zip','w') as zipObj:           \n",
    "    # Iterate over all the files in directory\n",
    "    for folderName, subfolders, filenames in os.walk(dirName):\n",
    "        print(folderName, subfolders, filenames )\n",
    "        for filename in filenames:\n",
    "            #create complete filepath of file in directory\n",
    "            filePath = os.path.join(folderName, filename)\n",
    "            # Add file to zip\n",
    "            zipObj.write(filePath, basename(filePath))\n",
    "\n",
    "            \n",
    "## https://www.kaggle.com/code/motono0223/guie-clip-tensorflow-train-example            \n",
    "# save_locally = tf.saved_model.SaveOptions(\n",
    "#     experimental_io_device='/job:localhost'\n",
    "# )\n",
    "# emb_model.save('./embedding_norm_model', options=save_locally)\n",
    "\n",
    "# from zipfile import ZipFile\n",
    "\n",
    "# with ZipFile('submission.zip','w') as zip:           \n",
    "#     zip.write(\n",
    "#         './embedding_norm_model/saved_model.pb', \n",
    "#         arcname='saved_model.pb'\n",
    "#     ) \n",
    "#     zip.write(\n",
    "#         './embedding_norm_model/variables/variables.data-00000-of-00001', \n",
    "#         arcname='variables/variables.data-00000-of-00001'\n",
    "#     ) \n",
    "#     zip.write(\n",
    "#         './embedding_norm_model/variables/variables.index', \n",
    "#         arcname='variables/variables.index'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Plotting\n",
    "\n",
    "The following plots show that the model has a hard time generalizing, as the val loss remains mostly flat while the loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.title(f\"Loss: {loss.name} - LR: {LR}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging deeper, thanks to the `SplitValidationLoss()` callback, we can contrast the binary accuracy for seen and unseen classes. This reveals that the model peak performance happend at epoch 2. As expected, there is a gap between the seen and unseen binary accuracy, however, this gap is fairly small which indicates that the model generalizes fairly well, even though it only trained on 42% of the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"binary_accuracy_known_classes\"])\n",
    "plt.plot(history.history[\"binary_accuracy_unknown_classes\"])\n",
    "plt.legend([\"binary_accuracy_known\", \"binary_accuracy_unknown\"])\n",
    "plt.title(f\"Known | Unknown binary_accuracy: {loss.name} - LR: {LR}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "We are going to index about 1000 examples from all 37 classes\n",
    "and use the remainder of the test dataset as unseen queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is indexed\n",
    "index_size = 360\n",
    "query_size = 360\n",
    "index_x, index_y = test_ds.get_slice(0, index_size)\n",
    "index_data = tf.cast(index_x, dtype=\"int32\")  # casted so it can displayed\n",
    "\n",
    "# what will be used as never seen before queries to test performance\n",
    "test_x, test_y = test_ds.get_slice(index_size, query_size)\n",
    "test_y = [int(c) for c in test_y]\n",
    "test_data = tf.cast(test_x, dtype=\"int32\")  # casted so it can displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_index()\n",
    "model.index(index_x, index_y, data=index_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Inspection of the Results\n",
    "\n",
    "As mentioned earlier, it may be difficult to get a sense of the model quality from the metrics alone. A complementary approach is to manually indpect a set of query results to get a sense of the match quality. Looking at the model result, while imperfect, still returns meaningfully similar results. The model is able to find images of similar looking animals irrespective of their pose or image illumination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "num_neigboors = 5\n",
    "idxs = random.sample(range(len(test_y)), num_examples)\n",
    "batch = tf.gather(test_x, idxs)\n",
    "nns = model.lookup(batch, k=num_neigboors)\n",
    "for bid, nn in zip(idxs, nns):\n",
    "    # view results close by\n",
    "    if test_y[bid] in train_cls:\n",
    "        display(Markdown(\"**Known Class**\"))\n",
    "    else:\n",
    "        display(Markdown(\"**Unknown Class**\"))\n",
    "    tfsim.visualization.viz_neigbors_imgs(test_data[bid], test_y[bid], nn, class_mapping=breeds, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize clusters\n",
    "\n",
    "One of the best ways to quickly get a sense of the quality of how the model is doing and understand it's short comings is to project the embedding into a 2D space. This allows us to inspect clusters of images and understand which classes are entangled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_clusters = 720  # @param {type:\"integer\"}\n",
    "thumb_size = 96  # @param {type:\"integer\"}\n",
    "plot_size = 800\n",
    "vx, vy = test_ds.get_slice(0, num_examples_to_clusters)\n",
    "tfsim.visualization.projector(\n",
    "    model.predict(vx), labels=vy, images=vx, class_mapping=breeds, image_size=thumb_size, plot_size=plot_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for following this tutorial till the end. If you are interested in learning about TensorFlow Similarity advanced features, you can checkout our other notebooks."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "interpreter": {
   "hash": "cada0c3e68bbe3038c05f3f13c34d05fb5411cc128b62a4a529880c33c3268c3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
