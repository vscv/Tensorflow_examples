{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 Course of transfer learning and Fine tune 2021-01-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  One cycle lr with period lr searching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.style.use(\"bmh\")\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import errno\n",
    "\n",
    "# albumentations\n",
    "from functools import partial\n",
    "# from albumentations import (\n",
    "#     Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n",
    "#     Rotate\n",
    "# )\n",
    "import albumentations as A\n",
    "\n",
    "# from adabelief_tf import AdaBeliefOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image size, Batch size, toe/heel-offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # 16 #32 #64 #128 #32 #64 #todo: reduce the BS maybe help to reduce the loss\n",
    "img_height = 120 #512 #224 #100\n",
    "img_width = 120 #512 #224 #100\n",
    "\n",
    "y_offset_toe = 80\n",
    "y_offset_heel = 280 #400-120=280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf MirroredStrategy seting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf MirroredStrategy seting\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print('\\nNumber of REPLICAS: {}\\n'.format(REPLICAS))\n",
    "\n",
    "\n",
    "MULTI_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "print('BATCH_SIZE: {}, MULTI_BATCH_SIZE: {}'.format(BATCH_SIZE, MULTI_BATCH_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動調節tf.data管道\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the training dataset W/ croped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load samples as data-farame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # data-org #\n",
    "# ann = 'annotation_1424_merge.csv'\n",
    "# im_p = 'train/images/'\n",
    "\n",
    "\n",
    "\n",
    "# # data-org-augm#\n",
    "# ann = 'annotation_2848_augm.csv'\n",
    "# im_p = 'train_augm/images/'\n",
    "# df[1335:]\n",
    "\n",
    "\n",
    "# data-train #\n",
    "ann = 'annotation_1345_good.csv'\n",
    "im_p = 'train/images/'\n",
    "\n",
    "# data-augm #\n",
    "# ann = 'annotation_2690_augm.csv'\n",
    "# im_p = 'train_augm/images/'\n",
    "\n",
    "# # data-train-HPL-1223\n",
    "# ann = 'annotation_1123_HPL_Good.csv'\n",
    "# im_p = 'train/images/'\n",
    "\n",
    "df = pd.read_csv(ann)\n",
    "df[1120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, the image_####.jpg now are random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tf.dataset (DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe\n",
    "list_ds = tf.data.Dataset.from_tensor_slices((df['images'], df['x1'], df['y1'], df['x2'], df['y2']))\n",
    "# list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds)#.shape() #take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check The type specification of an element of this dataset.\n",
    "list_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,x1,y1,x2,y2 in list_ds.take(5):\n",
    "    print(f'take sample: {f} {x1} {y1} {x2} {y2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np decode to UTF-8\n",
    "print(f.numpy().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ds iterator for consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python iterator\n",
    "\n",
    "it_list_ds = iter(list_ds) # Make sure iter ds only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using iter and consuming its elements using next: every print different image name.\n",
    "\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = next(it_list_ds)\n",
    "    print(image.numpy(), x1.numpy(), y1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = valid_ds_pre_s.as_numpy_iterator().next()\n",
    "# pred = model.predict_on_batch(image_batch)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = list_ds.as_numpy_iterator().next()# every time create a new iter, so need put iter out of above cell.\n",
    "    print(image, x1, y1, x2, y2)\n",
    "    \n",
    "iter_test_list = list_ds.as_numpy_iterator()\n",
    "print(\"===== Create iterator once and pull out to above cell. =====\")\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = iter_test_list.next()\n",
    "    print(image, x1, y1, x2, y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process path to image tensor in DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    boolen = parts[-2] == class_names\n",
    "    #one_hot_num = np.array(boolen, dtype=np.int) not works should use tf.x repalced.\n",
    "    one_hot_num = tf.dtypes.cast(boolen, tf.int64)\n",
    "    one_num = tf.argmax(one_hot_num)\n",
    "    print('one_num:', one_num)\n",
    "    # Integer encode the label\n",
    "    return one_num\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])# augment 已經resize過一次了 但這邊不先做會比較慢\n",
    "    return tf.cast(tf.image.resize(img, [img_height, img_width]), tf.uint8)# 避免float over at augment\n",
    "'''\n",
    "\n",
    "#\n",
    "# map list to ds, Toe part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_toe(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y1=y_offset_toe;    x1=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_toe(file_path,x1,y1,x2,y2):\n",
    "    file_path = im_p + file_path\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_toe(img)\n",
    "    return img, [x1,y1-y_offset_toe]#Original [0,120]\n",
    "    #return img, x1, y1-y_offset_toe #Original [0,120] #貌似ed不用改，蛋mse變超大\n",
    "    #return img, [x1/120,(y1-y_offset_toe)/120]#normalized [0,1] xy <dtype: 'float64'>, no help.\n",
    "    #return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] , no help.\n",
    "\n",
    "#\n",
    "# map list to ds, Heel part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_heel(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y2=y_offset_heel;    x2=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y2), int(x2), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_heel(file_path,x1,y1,x2,y2):\n",
    "    file_path = im_p + file_path\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_heel(img)\n",
    "    return img, [x2,y2-y_offset_heel]#Original [0,120]\n",
    "    #return img, x2, y2-y_offset_heel #Original [0,120] #貌似ed不用改，蛋mse變超大\n",
    "    #return img, [x2/120,(y2-y_offset_heel)/120]#normalized [0,1] xy <dtype: 'float64'>, no help.\n",
    "    #return img, [(x2-60)/60,((y2-y_offset_heel)-60)/60]#normalized [-1,1] , no help.\n",
    "\n",
    "#\n",
    "# test how to put parameters to map\n",
    "#\n",
    "\n",
    "def t_ds_map(file_path,x1,y1,x2,y2):\n",
    "#     img = get_img('train/images/' + str(file_path))\n",
    "#     print(file_path)\n",
    "    return file_path,x1,y1,x2,y2 #img, [x1,y1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toe ds\n",
    "train_ds_map_toe = list_ds.map(process_path_toe, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Heel ds\n",
    "train_ds_map_heel = list_ds.map(process_path_heel, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, xy in train_ds_map_toe.take(1):\n",
    "#     print(f'take sample: {xy}')\n",
    "    \n",
    "# print('f', f.dtype)\n",
    "# print('xy', xy.dtype)\n",
    "\n",
    "# for img, x, y in train_ds_map_toe.take(1):\n",
    "#     print(f'take sample: {x} {y}')\n",
    "    \n",
    "# print('img', img.dtype)\n",
    "# print('x', x.dtype)\n",
    "# x\n",
    "\n",
    "for img, [x, y] in train_ds_map_toe.take(1):\n",
    "    print(f'take sample: {x} {y}')\n",
    "    \n",
    "print('f', f.dtype)\n",
    "print('x', x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f,x1,y1,x2,y2 in train_ds_map.take(5):\n",
    "#     print(f'take sample: {f} {x1} {y1} {x2} {y2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [new] Split train_ds_pre with ratio of validation %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ToDo 20210201] keep orignal validation in 0.1, but augmenting train_ds in input layer or in the tf.ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Toe\n",
    "val_size = int(tf.data.experimental.cardinality(train_ds_map_toe).numpy() * 0.2)\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_map_toe).numpy() * 0.1)#no help\n",
    "\n",
    "train_ds_map_toe_s = train_ds_map_toe.skip(val_size)\n",
    "valid_ds_map_toe_s = train_ds_map_toe.take(val_size)\n",
    "\n",
    "print(len(train_ds_map_toe))\n",
    "print(val_size)\n",
    "print(tf.data.experimental.cardinality(train_ds_map_toe_s).numpy())\n",
    "print(tf.data.experimental.cardinality(valid_ds_map_toe_s).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split Heel\n",
    "val_size = int(tf.data.experimental.cardinality(train_ds_map_heel).numpy() * 0.2)\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_map_heel).numpy() * 0.1)\n",
    "\n",
    "\n",
    "train_ds_map_heel_s = train_ds_map_heel.skip(val_size)\n",
    "valid_ds_map_heel_s = train_ds_map_heel.take(val_size)\n",
    "\n",
    "print(len(train_ds_map_heel))\n",
    "print(val_size)\n",
    "print(tf.data.experimental.cardinality(train_ds_map_heel_s).numpy())\n",
    "print(tf.data.experimental.cardinality(valid_ds_map_heel_s).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albumentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for NO keypoint augment\n",
    "transforms = A.Compose([\n",
    "            A.RandomBrightness(limit=0.1, p=0.5),\n",
    "            A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "            A.RandomContrast(limit=0.2, p=0.5),\n",
    "            A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "            A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5), #0.8~0.99 may better\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "#             A.GlassBlur(sigma=0.9, max_delta=2, iterations=2, always_apply=False, mode='fast', p=0.5),\n",
    "#             A.GaussNoise(var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5),\n",
    "#             A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=0.5),\n",
    "#             A.HorizontalFlip(),\n",
    "])\n",
    "\n",
    "\n",
    "def aug_fn(image, img_size):\n",
    "    data = {\"image\":image}\n",
    "    aug_data = transforms(**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "#     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.cast(aug_img, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "    return aug_img\n",
    "\n",
    "def process_data(image, label, img_size):\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "    return aug_img, label\n",
    "\n",
    "def set_shapes(img, label, img_shape=(120,120,3)):\n",
    "    img.set_shape(img_shape)\n",
    "#     label.set_shape([]) # commited for go around error\n",
    "    return img, label\n",
    "\n",
    "\n",
    "\n",
    "# # for NO keypoint augment AND for OneOf[] for better heel loss.\n",
    "# transforms_oneof = A.Compose(A.OneOf([\n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "#             A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "#             A.GlassBlur(sigma=0.9, max_delta=2, iterations=2, always_apply=False, mode='fast', p=0.5),\n",
    "#             A.GaussNoise(var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5),\n",
    "#             A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=.5)\n",
    "# #             A.HorizontalFlip(),\n",
    "#             ]),p=0.5)\n",
    "\n",
    "\n",
    "# def aug_fn_oneof(image, img_size):\n",
    "#     data = {\"image\":image}\n",
    "#     aug_data = transforms_oneof(**data)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "# #     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "#     aug_img = tf.cast(aug_img, tf.float32)\n",
    "#     aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "#     return aug_img\n",
    "\n",
    "# def process_data_oneof(image, label, img_size):\n",
    "#     aug_img = tf.numpy_function(func=aug_fn_oneof, inp=[image, img_size], Tout=tf.float32)\n",
    "#     return aug_img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Testing keypoints augment\n",
    "# transforms = A.Compose([\n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA (alpha=0.1, always_apply=False, p=1),\n",
    "#             A.Downscale (scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             ]\n",
    "#             , \n",
    "#             keypoint_params=A.KeypointParams(format='xy'),  #currently not works for tf.ds yet.\n",
    "#             )\n",
    "\n",
    "\n",
    "\n",
    "# # Testing keypoints augment\n",
    "# # @tf.function\n",
    "# def aug_fn(image, keypoints, img_size):\n",
    "# #     print('Check keypoints aug_fun 00:', keypoints) # Check keypoints aug_fun 00: [[53 58]]\n",
    "# #     data = {\"image\":image}\n",
    "#     aug_data = transforms(image=image, keypoints=keypoints)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "#     aug_xy  = aug_data[\"keypoints\"]\n",
    "# #     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "#     aug_img = tf.cast(aug_img, tf.float32)\n",
    "#     aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "# #     print('Check aug_xy:', aug_xy) # Check aug_xy: [(95, 45)]\n",
    "#     return aug_img, aug_xy \n",
    "\n",
    "# # @tf.function\n",
    "# def process_data(image, keypoints, img_size):\n",
    "    \n",
    "# #     print('Check keypoints process01:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "        \n",
    "# #     keypoints = tf.make_ndarray(keypoints)\n",
    "# #     keypoints = np.array(keypoints)\n",
    "# #     keypoints = list(keypoints)\n",
    "# #     keypoints = np.asarray(keypoints, dtype=np.float32)\n",
    "# #     keypoints = tf.make_ndarray(keypoints.op.get_attr('value'))\n",
    "\n",
    "# #     keypoints = tf.reshape(keypoints, [1, 2])\n",
    "#     keypoints = tf.reshape(keypoints, [1, 2]) # for 'convert_keypoint_to_albumentations'\n",
    "# #     keypoints = np.reshape(keypoints, (1, 2))#not support tensor with np.call.\n",
    "\n",
    "# #     print('Check keypoints process02:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "\n",
    "# #     aug_img, aug_xy = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "# #     aug_img, aug_xy = tf.py_function(func=aug_fn, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.int64])#for tensors.\n",
    "#     aug_img, aug_xy = tf.numpy_function(func=aug_fn, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.int64])\n",
    "# #     print('Check keypoints process03:', aug_xy)\n",
    "    \n",
    "#     aug_xy = tf.reshape(keypoints, [2,]) # for 'tf ds tarining'\n",
    "# #     print('Check keypoints process04:', aug_xy)\n",
    "        \n",
    "#     return aug_img, aug_xy \n",
    "\n",
    "\n",
    "# def set_shapes(img, label, img_shape=(120,120,3)):\n",
    "#     img.set_shape(img_shape)\n",
    "# #     label.set_shape([]) # commited for go around error\n",
    "#     return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare train_ds_prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance_cache_train(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache.\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "        ds = ds.map(partial(process_data, img_size=120),num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "    ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def configure_for_performance_cache_train_oneof(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache.\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "        ds = ds.map(partial(process_data_oneof, img_size=120),num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "    ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def configure_for_performance_cache_val(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache\n",
    "    TODO:test remove ds.shuffle from val_ds.\n",
    "    .\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "#         ds = ds.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(AA, num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(RA, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "#     ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=False) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "# \"\"\"\n",
    "# # Toe ds_pre\n",
    "# train_ds_pre_toe = configure_for_performance_cache_train(train_ds_map_toe)\n",
    "\n",
    "# # Heel ds_pre\n",
    "# train_ds_pre_heel = configure_for_performance_cache_val(train_ds_map_heel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All split ds_prefetch\n",
    "* train_ds_map_toe_s = train_ds_map_toe.skip(val_size)\n",
    "* valid_ds_map_toe_s = train_ds_map_toe.take(val_size)\n",
    "\n",
    "* train_ds_map_heel_s = train_ds_map_heel.skip(val_size)\n",
    "* valid_ds_map_heel_s = train_ds_map_heel.take(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "\"\"\"\n",
    "# Toe ds_pre\n",
    "train_ds_pre_toe_s = configure_for_performance_cache_train(train_ds_map_toe_s, augment=True)\n",
    "valid_ds_pre_toe_s = configure_for_performance_cache_val(valid_ds_map_toe_s)\n",
    "\n",
    "# Heel ds_pre\n",
    "train_ds_pre_heel_s = configure_for_performance_cache_train(train_ds_map_heel_s, augment=True)\n",
    "valid_ds_pre_heel_s = configure_for_performance_cache_val(valid_ds_map_heel_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ds_prefetch samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create it_ds once\n",
    "it_train_ds_pre_toe_s = iter(train_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# for albu keypoint\n",
    "\n",
    "# for original return aug_img, , aug_xy \n",
    "\n",
    "\n",
    "image_batch, label_batch = next(it_train_ds_pre_toe_s)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(label_batch[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "    print(f'Check lables: {label_batch[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create it_ds once\n",
    "it_train_ds_pre_heel_s = iter(train_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# for albu keypoint\n",
    "\n",
    "# for original return aug_img, , aug_xy \n",
    "\n",
    "\n",
    "image_batch, label_batch = next(it_train_ds_pre_heel_s)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(label_batch[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "    print(f'Check lables: {label_batch[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create it_ds once\n",
    "it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# for albu keypoint\n",
    "\n",
    "# for return aug_img, aug_xy \n",
    "\n",
    "\n",
    "image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "# for images, labels in valid_ds_pre_toe_s.take(1):\n",
    "print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(label_batch[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "    print(f'Check lables: {label_batch[i]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #2021-01-30\n",
    "# # for change default [x, y] tuple to x, y\n",
    "\n",
    "# # plot_number_of_sample = MULTI_BATCH_SIZE\n",
    "# # col_size = row_size = int(np.sqrt(MULTI_BATCH_SIZE))\n",
    "# # # row_size = np.sqrt(MULTI_BATCH_SIZE)\n",
    "# # print(col_size)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for images, x, y in train_ds_pre_toe_s.take(1):\n",
    "#     print('batch * multi:', len(labels), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title([labels[i].numpy()])\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#         plt.plot(x[i].numpy(), y[i].numpy(), 'r+', markersize=13, mew=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # plot_number_of_sample = MULTI_BATCH_SIZE\n",
    "# # col_size = row_size = int(np.sqrt(MULTI_BATCH_SIZE))\n",
    "# # # row_size = np.sqrt(MULTI_BATCH_SIZE)\n",
    "# # print(col_size)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for images, labels in train_ds_pre_toe_s.take(1):\n",
    "#     print('batch * multi:', len(labels), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title([labels[i].numpy()])\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#         plt.plot(labels[i].numpy()[0], labels[i].numpy()[1], 'r+', markersize=13, mew=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # NOrmalized xy to [0, 1] #\n",
    "\n",
    "# # plot_number_of_sample = MULTI_BATCH_SIZE\n",
    "# # col_size = row_size = int(np.sqrt(MULTI_BATCH_SIZE))\n",
    "# # # row_size = np.sqrt(MULTI_BATCH_SIZE)\n",
    "# # print(col_size)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for images, labels in train_ds_pre_toe_s.take(1):\n",
    "#     print('batch * multi:', len(labels), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title([labels[i].numpy()])\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#         plt.plot(labels[i].numpy()[0]*120, labels[i].numpy()[1]*120, 'r+', markersize=13, mew=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # NOrmalized xy to [0, 1] #\n",
    "\n",
    "# # plot_number_of_sample = MULTI_BATCH_SIZE\n",
    "# # col_size = row_size = int(np.sqrt(MULTI_BATCH_SIZE))\n",
    "# # # row_size = np.sqrt(MULTI_BATCH_SIZE)\n",
    "# # print(col_size)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for images, labels in train_ds_pre_heel_s.take(1):\n",
    "#     print('batch * multi:', len(labels), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title([labels[i].numpy()])\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#         plt.plot(labels[i].numpy()[0]*120, labels[i].numpy()[1]*120, 'r+', markersize=13, mew=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for images, labels in train_ds_pre_heel_s.take(1):\n",
    "#     print('batch * multi:', len(labels))\n",
    "#     for i in range(16):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(str(labels[i].numpy()))\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#         plt.plot(labels[i].numpy()[0], labels[i].numpy()[1], 'b+', markersize=13, mew=2.5)\n",
    "# #         print((labels[i].numpy()[0], labels[i].numpy()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create it_ds once\n",
    "# it_train_ds_pre_toe = iter(train_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = next(it_train_ds_pre_toe)\n",
    "\n",
    "# plt.figure(figsize=(18, 18))\n",
    "# for i in range(64):\n",
    "#     ax = plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title('x1,y1:' + str(label_batch[i].numpy()))\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     #print(label_batch[i])\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OLD] Split train_ds_pre\n",
    "\n",
    "##### train_ds_pre_s\n",
    "##### valid_ds_pre_s \n",
    "\n",
    "### re-set to toe/heel split\n",
    "##### train_ds_pre_toe_s\n",
    "##### valid_ds_pre_toe_s\n",
    "\n",
    "##### train_ds_pre_heel_s\n",
    "##### valid_ds_pre_heel_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split Toe\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_pre_toe).numpy() * 0.2)\n",
    "\n",
    "# train_ds_pre_toe_s = train_ds_pre_toe.skip(val_size)\n",
    "# valid_ds_pre_toe_s = train_ds_pre_toe.take(val_size)\n",
    "\n",
    "# print(len(train_ds_pre_toe))\n",
    "# print(val_size)\n",
    "# print(tf.data.experimental.cardinality(train_ds_pre_toe_s).numpy())\n",
    "# print(tf.data.experimental.cardinality(valid_ds_pre_toe_s).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split Heel\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_pre_heel).numpy() * 0.2)\n",
    "\n",
    "# train_ds_pre_heel_s = train_ds_pre_heel.skip(val_size)\n",
    "# valid_ds_pre_heel_s = train_ds_pre_heel.take(val_size)\n",
    "\n",
    "# print(len(train_ds_pre_heel))\n",
    "# print(val_size)\n",
    "# print(tf.data.experimental.cardinality(train_ds_pre_heel_s).numpy())\n",
    "# print(tf.data.experimental.cardinality(valid_ds_pre_heel_s).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Loss function\n",
    "\n",
    "* mae\n",
    "* euclidean distance\n",
    "* others\n",
    "\n",
    "\n",
    "        # 'x' is [[1, 1, 1]\n",
    "        #         [1, 1, 1]]\n",
    "        tf.reduce_sum(x) ==> 6\n",
    "        tf.reduce_sum(x, 0) ==> [2, 2, 2]\n",
    "        tf.reduce_sum(x, 1) ==> [3, 3]\n",
    "        the function is default for 2-D array, therefor, in our 1-D [x1,y1] to [x2,y2] the axis should be '0' or just leave it.\n",
    "        \n",
    "        tf.sqrt need \tA tf.Tensor of type bfloat16, half, float32, float64, complex64, complex128\n",
    "        so, convert it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be -> tf.Tensor([56 39], shape=(2,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [10, 10]\n",
    "y_pred = [10, 20]\n",
    "\n",
    "# y_true = [1.00000000000000000000123, 10]\n",
    "# y_pred = [1.0, 10.000000000000000000000000001]\n",
    "\n",
    "# y_true = [1.0000123, 10]\n",
    "# y_pred = [1.0, 10.0000321]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae\n",
    "\n",
    "loss_mae = tf.keras.losses.MAE(\n",
    "    y_true, y_pred\n",
    ")\n",
    "\n",
    "loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ed\n",
    "\n",
    "# loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.constant(y_true) - tf.constant(y_pred)), 0))\n",
    "\n",
    "# loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.Variable(y_true) - tf.Variable(y_pred)), 0))\n",
    "\n",
    "loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0))\n",
    "\n",
    "loss_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ed_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0))\n",
    "\n",
    "# fix NaN in euclidean distance\n",
    "# tf.maximum(d, 1e-9), to keep atlease is 1e-9.\n",
    "# def ed_loss(y_true, y_pred):\n",
    "#     return tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0), 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the euclidean distance loss\n",
    "ed_loss(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean Euclidean distance \n",
    "\n",
    "* here the y_true and y_pred is 2-D array. the axis use 1.\n",
    "\n",
    "\n",
    "* NOTE: LB評分的mean euclidean distance功能，應該跟model.evaluate()一樣so不需重新寫。evaluate()會自動用loss (model.metrics_names)計算後在自動平均，而模型loss我們是用ed-loss取代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [[60, 76],\n",
    "#        [58, 49 ],\n",
    "#        [63, 67 ],\n",
    "#        [58 , 57]]\n",
    "# y_pred = [[59.927303, 76.471214],\n",
    "#        [58.056904, 49.98754 ],\n",
    "#        [63.067844, 67.03861 ],\n",
    "#        [58.70202 , 57.372707]]\n",
    "\n",
    "y_true = [[60, 70],\n",
    "       [70, 80]]\n",
    "y_pred = [[61, 71],\n",
    "       [72, 82]]\n",
    "\n",
    "# y_true = [(60, 70),\n",
    "#        (70, 80)]\n",
    "# y_pred = [(61, 71),\n",
    "#        (72, 82)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ed_metric_2d(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等於true, pred點位ed的平均，LB評分方式。(toe/heel即p1,p2要個別算ed一次再相加)\n",
    "def ed_metric_2d_mean(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for re-scale back xy \n",
    "# return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "# return img, [(x2-60)/60,((y2-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "\n",
    "# 等於true, pred點位ed的平均，LB評分方式。(toe/heel即p1,p2要個別算ed一次再相加)\n",
    "def edRescal(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(tf.cast((y_true*60)+60, tf.float32) - tf.cast((y_pred*60)+60, tf.float32)), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d_mean(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d_mean(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test howto contact the all pred reuslt for submit.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append test\n",
    "aa= [[ 32.0332  , 105.49409 ],\n",
    "       [ 68.21191 ,  83.02111 ],\n",
    "       [ 32.07095 ,  99.04422 ]]\n",
    "bb= [[ 11.0332  , 22.49409 ],\n",
    "       [ 33.21191 ,  44.02111 ]]\n",
    "all_pred = np.append(aa, bb, axis=0)#上下接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_12 = np.append(all_pred, all_pred, axis=1)#左右接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi output regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras \n",
    "# from tensorflow.keras import models\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "# model_name = 'simple-Conv2D'\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(Conv2D(16, (3, 3), input_shape=(120, 120, 3), activation='relu'))#fix by filters, (ks,ks)\n",
    "# # model.add(Conv2D(3, 3, input_shape=(120, 120, 3), activation='relu'))# still run\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(500, activation='relu'))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(20, activation='relu'))\n",
    "# model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep_num = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss=ed_metric_2d_mean)#, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "# #     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=100), #patience=step_size ot ep_num\n",
    "#     tf.keras.callbacks.LearningRateScheduler(clr3),#,clr2_heel  lrfn2_heel decay or lrfn or lrfn2. clr\n",
    "# #     lr_reduceonplateau,\n",
    "# #     PrintLRheel()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # fit the model on all data\n",
    "\n",
    "# ### re-set to toe/heel split\n",
    "# ##### train_ds_pre_toe_s\n",
    "# ##### valid_ds_pre_toe_s\n",
    "# model.fit(train_ds_pre_toe_s, verbose=1, epochs=ep_num, validation_data=valid_ds_pre_toe_scallbacks=callbacks)#, validation_split=0.1)\n",
    "\n",
    "# ##### train_ds_pre_heel_s\n",
    "# ##### valid_ds_pre_heel_s\n",
    "# # model.fit(train_ds_pre_heel_s, verbose=1, epochs=ep_num, validation_data=valid_ds_pre_heel_s)#, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(valid_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFNE Training for period lr searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe mae better than ed loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay (todo)\n",
    "# ##  One cycle lr with period lr searching ![image.png](attachment:image.png)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def decay(epoch):\n",
    "   initial_lrate = 0.0000001\n",
    "   k = 0.09\n",
    "   t = epoch * 0.5\n",
    "   lrate = initial_lrate * np.exp(k*t) # t is iteration number. (+k)\n",
    "   return lrate\n",
    "\n",
    "# # step decay\n",
    "# def decay(epoch):\n",
    "#    initial_lrate = base_learning_rate\n",
    "#    drop = 0.5\n",
    "#    epochs_drop = 20.0\n",
    "#    lrate = initial_lrate * tf.math.pow(drop, tf.math.floor((1+epoch)/epochs_drop))\n",
    "#    return lrate\n",
    "\n",
    "ep_num_lr_search = 300\n",
    "\n",
    "rng = [i for i in range(ep_num_lr_search)]\n",
    "y = [decay(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.12f'))\n",
    "plt.plot(rng, y)\n",
    "\n",
    "print(\"e0    lr:\", y[0])\n",
    "print(\"e50   lr:\", y[50])\n",
    "print(\"e100  lr:\", y[100])\n",
    "print(\"e150  lr:\", y[150])\n",
    "print(\"e200  lr:\", y[200])\n",
    "print(\"e250  lr:\", y[250])\n",
    "print(\"e300  lr:\", y[300-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e, lr in zip(rng,y):\n",
    "    print('{}\\t {}\\n'.format(e, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dump lr\n",
    "\"\"\"\n",
    "ep_num_transf = 500\n",
    "\n",
    "\n",
    "\n",
    "def lrdump(epoch):\n",
    "    \n",
    "    #step_size = 100\n",
    "    lr_max = 0.006\n",
    "    lr_min = 0.001\n",
    "    lr_start = 0.01\n",
    "\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 100\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "\n",
    "    \n",
    "    # warm up\n",
    "    if epoch < lr_init_ep:\n",
    "        lr = (lr_max - lr_min) / lr_ramp_ep * epoch + lr_min    \n",
    "        \n",
    "    elif lr_init_ep -1 < epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(ep_num_transf)]\n",
    "y = [lrdump(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e, lr in zip(rng,y):\n",
    "    print('{}\\t {}\\n'.format(e, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_reduceonplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLRtoe(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "#             datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "#             epoch + 1,\n",
    "#             self.model.optimizer.lr.numpy()))\n",
    "        print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "        epoch + 1,\n",
    "        model_toe.optimizer._decayed_lr(tf.float32).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLRheel(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "#                                               model_heel.optimizer.lr.numpy()))\n",
    "        print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "        epoch + 1,\n",
    "        model_heel.optimizer._decayed_lr(tf.float32).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output dir and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_log_dir(log_dir_name):\n",
    "    try:\n",
    "        os.makedirs(log_dir_name)\n",
    "    except OSError as e:\n",
    "        print(\"This log dir exist.\")\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise ValueError(\"we got problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = 'val_loss' #'val_loss' 'val_accuracy' if use ed_loss it still the loss here.\n",
    "\n",
    "log_dir_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "\n",
    "# mk_log_dir(datetime.now().strftime(\"%Y%m%d-%H%M%S\") )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use once at the time\n",
    "mk_log_dir(log_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'EfficientNetB0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_best_model_name\n",
    "\n",
    "# best_model_name = './' + model_name + '_bs-' + str(BATCH_SIZE) + '_s-' + str(img_height) + '_' + \"ep-{epoch:02d}-vloss-{val_loss:.2f}\" +'_best-weight.h5'\n",
    "# best_model_name = '{model_name}-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "#best_model_name = './' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + monitor + '_best.h5'\n",
    "# best_model_name = './Leaf_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_best_' + monitor + '.h5'\n",
    "\n",
    "# best_model_name = './cop' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_best_' + monitor + '.h5'\n",
    "\n",
    "def get_best_model_name(th):\n",
    "    return './' + log_dir_name + '/' + th + '_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_best_' + monitor + '.h5'\n",
    "\n",
    "th = 'toe'\n",
    "# th = 'heel'\n",
    "\n",
    "print(get_best_model_name(th))\n",
    "\n",
    "best_model_name = get_best_model_name(th)\n",
    "\n",
    "\n",
    "best_model_save = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_name, \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = False,\n",
    "                             monitor = monitor, \n",
    "                             mode = 'auto', verbose = 1)\n",
    "print('best_model_name:', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir_name + \"/logs/toe/\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=20), #patience=step_size or ep_num\n",
    "#     lr_reduceonplateau,\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),#lrdump, decay or lrfn or lrfn2. clr\n",
    "#     PrintLRtoe()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create keras model\n",
    "\n",
    "# model_name = 'EfficientNetB0'\n",
    "\n",
    "# top_dropout_rate = 0.8 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "# drop_connect_rate = 0.9 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "# outputnum = 2\n",
    "\n",
    "# with strategy.scope():\n",
    "    \n",
    "#     base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\",drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "\n",
    "#     # Freeze the pretrained weights\n",
    "#     base_model.trainable = False\n",
    "#     print(\"base_model.trainable : \", base_model.trainable)\n",
    "\n",
    "#     # Rebuild top\n",
    "#     gap2d = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "#     BNL = tf.keras.layers.BatchNormalization()(gap2d) #tood: remove#\n",
    "#     dropout = tf.keras.layers.Dropout(top_dropout_rate)(BNL)#tood: remove# J add dropout, for flood 0.2 is ok. for leaf 0.4 is better.\n",
    "#     outputs = tf.keras.layers.Dense(2)(dropout)# remove activation for regression output (to default, the linear), , activation = 'relu' no help\n",
    "\n",
    "#     # Compile new model\n",
    "#     model_toe = tf.keras.Model(base_model.input, outputs, name=model_name)\n",
    "\n",
    "\n",
    "#     # unfreeze the top #fine_tune_at# layers while leaving BatchNorm layers frozen\n",
    "#     fine_tune_at = 20 #10 #241 #20\n",
    "#     print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "#     for layer in model_toe.layers[-fine_tune_at:]:\n",
    "#         if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "#     model_toe.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "#                     loss=ed_metric_2d_mean)\n",
    "#                       #metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "#                       #metrics=[edRescal])\n",
    "    \n",
    "# #     loss=tf.keras.losses.MeanSquaredError()\n",
    "#                     #ed_metric_2d_mean,#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                     #metrics=['mae', 'accuracy'])#!!note!! for keypoint regression should use MSE loss 01/29#\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# # # AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-14, rectify=False)\n",
    "# # model_toe.compile(optimizer = AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-14, rectify=False),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "# #                 loss=ed_metric_2d_mean)#,#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "# #                 #metrics=['mae', 'accuracy'])\n",
    "\n",
    "\n",
    "# # =========================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transfer learning from pre-trained weights\n",
    "def build_efn_model(outputnum, top_dropout_rate, drop_connect_rate):\n",
    "    base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(120,120,3),drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    base_model.trainable = False\n",
    "    print(\"base_model.trainable : \", base_model.trainable)\n",
    "\n",
    "    # Rebuild top\n",
    "    gap2d = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    BNL = tf.keras.layers.BatchNormalization()(gap2d) #tood: remove#\n",
    "    dropout = tf.keras.layers.Dropout(top_dropout_rate)(BNL)#tood: remove# J add dropout, for flood 0.2 is ok. for leaf 0.4 is better.\n",
    "    outputs = tf.keras.layers.Dense(outputnum)(dropout)# remove activation for regression output (to default, the linear), , activation = 'relu' no help\n",
    "\n",
    "    # Compile new model\n",
    "    model = tf.keras.Model(base_model.input, outputs, name=model_name)\n",
    "\n",
    "\n",
    "#     # unfreeze the top #fine_tune_at# layers while leaving BatchNorm layers frozen\n",
    "#     fine_tune_at = 20 #10 #241 #20\n",
    "#     print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "#     for layer in model_toe.layers[-fine_tune_at:]:\n",
    "#         if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_dropout_rate = 0.8 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "drop_connect_rate = 0.9 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "outputnum = 2\n",
    "with strategy.scope():\n",
    "    model_toe = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_toe.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 0\n",
    "nt = 0\n",
    "for layer in model_toe.layers:\n",
    "    if layer.trainable:\n",
    "        tt +=1\n",
    "        print(f'{layer.name}')\n",
    "    else:\n",
    "        nt +=1\n",
    "print(f'tt: {tt}, nt:{nt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_trainOrNot_layers(model, printlayers=False):\n",
    "    tt = 0\n",
    "    nt = 0\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            tt +=1\n",
    "            if printlayers:\n",
    "                print(f'{layer.name}')\n",
    "        else:\n",
    "            nt +=1\n",
    "    print(f'tt: {tt}, nt:{nt}, total layers:{tt+nt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model on all data\n",
    "history_toe = model_toe.fit(train_ds_pre_toe_s, \n",
    "                      verbose=1, \n",
    "                      epochs=ep_num_lr_search, \n",
    "                      validation_data=valid_ds_pre_toe_s, \n",
    "                      callbacks=callbacks)#, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vis log(lr)\n",
    "#  a list of loss or lr, no index.\n",
    "# history_toe.history['val_loss']\n",
    "# history_toe.history['lr']\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_toe.history['lr'], history_toe.history['val_loss'])\n",
    "plt.xscale('log')\n",
    "plt.title('Search lr_max')\n",
    "\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('lr (log)')\n",
    "plt.legend(['loss@lr'], loc='upper right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min lose at epoch 235\n",
    "np.argmin(history_toe.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr at ep 235\n",
    "history_toe.history['lr'][235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train split有區域最小的問題，相同ds但最佳收斂點不同！\"\"\"\n",
    "\"\"\"KFold split may have same issue.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model_toe, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show after modl.fit\n",
    "model_toe.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metrics the model have.\n",
    "history_toe.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_toe.history['loss'])\n",
    "plt.plot(history_toe.history['val_loss'])\n",
    "plt.title('model ed loss')\n",
    "plt.ylabel('ed loss')#, plt.ylim(5, 20)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}_toe_tl.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('model ed loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color)\n",
    "\n",
    "ax1.plot(history_toe.history['loss'])\n",
    "ax1.plot(history_toe.history['val_loss'])\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_toe.history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(['lr'], loc='upper right') \n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "def get_valloss(his_v_l):   \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_toe.history['val_loss'])\n",
    "plt.savefig(f'{log_dir_name}_toe_tl_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toe Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clr3\n",
    "# warm up 10% of epoch: it can reduce fall in local min in inital steps.\n",
    "\n",
    "\n",
    "ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "def clr3(epoch):\n",
    "    \n",
    "    \n",
    "    step_size = 25 # currently best for foot pp\n",
    "    max_lr = 0.01 # currently best for foot pp\n",
    "    base_lr = 1e-6 # 1e-6 1e-7\n",
    "\n",
    "    # warm up\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 100\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.5\n",
    "\n",
    "    iterations = epoch\n",
    "    cycle = np.floor(1+iterations/(2*step_size))\n",
    "    x = np.abs(iterations/step_size - 2*cycle + 1)\n",
    "    lr = base_lr + (max_lr-base_lr)*np.maximum(0, (1-x))\n",
    "    \n",
    "    #todo: boost the lr at initial setps.\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else max_lr\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else boost_lr\n",
    "#     lr = initial_lr(epoch)\n",
    "    #todo: boost the lr at fist step_size.\n",
    "    \n",
    "    # warm up\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = (max_lr - base_lr) / lr_ramp_ep * epoch + base_lr\n",
    "    \n",
    "    decay = ((epoch+1)/ep_num)\n",
    "    base_part = 1.001 #1.1\n",
    "#     print(decay)\n",
    "    return lr * (base_part-decay) * lr_decay # supressed the lr!\n",
    "\n",
    "\n",
    "rng = [i for i in range(ep_num)]\n",
    "y = [clr3(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr from kaggle leaf\"\"\"\n",
    "ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "def lrfn2(epoch):\n",
    "    \n",
    "    lr_start   = 0.000005\n",
    "    # lr_max     = 0.00000125 * strategy.num_replicas_in_sync * BATCH_SIZE\n",
    "    lr_max     = 0.001\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 50\n",
    "    lr_sus_ep  = 20\n",
    "    lr_decay   = 0.95\n",
    "\n",
    "\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "    return lr\n",
    "\n",
    "\n",
    "\n",
    "rng = [i for i in range(ep_num)]\n",
    "y = [lrfn2(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model):\n",
    "#     # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
    "#     for layer in model.layers[-20:]:\n",
    "#         if not isinstance(layer, layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "#     model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     fine_tune_at = 20 #10 #241 #20\n",
    "#     print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "#     for layer in model_toe.layers[-fine_tune_at:]:\n",
    "#         if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "\n",
    "#\n",
    "#'block7a_expand_conv'20 'block6c_expand_conv'50 'block6a_expand_conv'79 'block5b_expand_conv'109 'block4a_expand_conv' 166 \n",
    "#\n",
    "\n",
    "    model.trainable = True\n",
    "    set_trainable = False\n",
    "    for layer in model.layers:\n",
    "        if layer.name == 'block5b_expand_conv': \n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze for finetune the toe model  \n",
    "unfreeze_model(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=100), #patience=step_size or ep_num\n",
    "#     lr_reduceonplateau,\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),#lrdump, decay or lrfn or lrfn2. clr, CosineDecayCLRWarmUp\n",
    "#     PrintLRtoe()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model on all data\n",
    "history_toe_finetune = model_toe.fit(train_ds_pre_toe_s, \n",
    "                      verbose=1, \n",
    "                      epochs=ep_num_lr_search, \n",
    "                      validation_data=valid_ds_pre_toe_s, \n",
    "                      callbacks=callbacks)#, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vis log(lr)\n",
    "#  a list of loss or lr, no index.\n",
    "# history_toe.history['val_loss']\n",
    "# history_toe.history['lr']\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_toe_finetune.history['lr'], history_toe_finetune.history['val_loss'])\n",
    "plt.xscale('log')\n",
    "plt.title('Search lr_max @FT')\n",
    "\n",
    "plt.ylabel('val_loss'), plt.ylim(0,50)\n",
    "plt.xlabel('lr (log)')\n",
    "plt.legend(['loss@lr'], loc='upper right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min lose at epoch 235\n",
    "np.argmin(history_toe_finetune.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr at ep 235\n",
    "history_toe_finetune.history['lr'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_toe_finetune.history['loss'])\n",
    "plt.plot(history_toe_finetune.history['val_loss'])\n",
    "plt.title('model ed loss')\n",
    "plt.ylabel('ed loss'), plt.ylim(4, 10)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}_toe_ft.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('[ toe_finetune ] \\n ED loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color)\n",
    "\n",
    "ax1.plot(history_toe_finetune.history['loss'])\n",
    "ax1.plot(history_toe_finetune.history['val_loss'])\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_toe_finetune.history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(['lr'], loc='upper right') \n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "def get_valloss(his_v_l):   \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "plt.savefig(f'{log_dir_name}_toe_ft_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valloss(his_v_l):\n",
    "     \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "\n",
    "vl, ep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_valloss(his_v_l):\n",
    "     \n",
    "    print(f'val_loss: {np.min(his_v_l)} at epoch {np.argmin(his_v_l)}.')\n",
    "    \n",
    "print_valloss(history_toe_finetune.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_toe, to_file='model_toe_conv_layer_blocks.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model_toe_conv_layer_blocks.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the mean-Euclidean Distance of test data\n",
    "\n",
    "may modify the ed-loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean ed-loss == mean ed of test data.\n",
    "model_toe.evaluate(valid_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dump lr\n",
    "\"\"\"\n",
    "ep_num_transf = 500\n",
    "\n",
    "\n",
    "\n",
    "def lrdump(epoch):\n",
    "    \n",
    "    #step_size = 100\n",
    "    lr_max = 0.006\n",
    "    lr_min = 0.001\n",
    "    lr_start = 0.01\n",
    "\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 0\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "\n",
    "    if lr_init_ep -1 < epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(ep_num_transf)]\n",
    "y = [lrdump(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# lr_reduceonplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor, \n",
    "#                                                           factor=0.5, \n",
    "#                                                           patience=15, \n",
    "#                                                           verbose=1, \n",
    "#                                                           mode='auto', \n",
    "#                                                           #min_delta=0.0001, \n",
    "#                                                           cooldown=5, \n",
    "#                                                           #min_lr=1e-12\n",
    "#                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_name(th):\n",
    "    return './' + log_dir_name + '/' + th + '_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_best_' + monitor + '.h5'\n",
    "\n",
    "# th = 'toe'\n",
    "th = 'heel'\n",
    "\n",
    "print(get_best_model_name(th))\n",
    "\n",
    "best_model_name = get_best_model_name(th)\n",
    "\n",
    "\n",
    "best_model_save = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_name, \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = False,\n",
    "                             monitor = monitor, \n",
    "                             mode = 'auto', verbose = 1)\n",
    "print('best_model_name:', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir_name + \"/logs/heel/\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=10), #patience=step_size ot ep_num\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),#,clr2_heel  lrfn2_heel decay or lrfn or lrfn2. clr\n",
    "#     lr_reduceonplateau,\n",
    "    PrintLRheel()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Heel-tf model\n",
    "top_dropout_rate = 0.4 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "drop_connect_rate = 0.4 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "outputnum = 2\n",
    "with strategy.scope():\n",
    "    model_heel = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model on all data\n",
    "history_heel = model_heel.fit(train_ds_pre_heel_s, \n",
    "                      verbose=1, \n",
    "                      epochs=ep_num_lr_search, \n",
    "                      validation_data=valid_ds_pre_heel_s, \n",
    "                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vis log(lr)\n",
    "#  a list of loss or lr, no index.\n",
    "# history_toe.history['val_loss']\n",
    "# history_toe.history['lr']\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_heel.history['lr'], history_heel.history['val_loss'])\n",
    "plt.xscale('log')\n",
    "plt.title('Search lr_max @FT')\n",
    "\n",
    "plt.ylabel('val_loss'), plt.ylim(0,50)\n",
    "plt.xlabel('lr (log)')\n",
    "plt.legend(['loss@lr'], loc='upper right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_heel.history['loss'])\n",
    "plt.plot(history_heel.history['val_loss'])\n",
    "plt.title('model ed loss')\n",
    "plt.ylabel('ed loss'), plt.ylim(3, 20)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}_heel_tl', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "\n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('model ed loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color)\n",
    "\n",
    "ax1.plot(history_heel.history['loss'])\n",
    "ax1.plot(history_heel.history['val_loss'])\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_heel.history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "def get_valloss(his_v_l):   \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_heel.history['val_loss'])\n",
    "plt.savefig(f'{log_dir_name}_heel_tl_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valloss(his_v_l):\n",
    "     \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_heel.history['val_loss'])\n",
    "\n",
    "vl, ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heel Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clr3\n",
    "# warm up 10% of epoch: it can reduce fall in local min in inital steps.\n",
    "\n",
    "\n",
    "ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "def clr3(epoch):\n",
    "    \n",
    "    \n",
    "    step_size = 25 # currently best for foot pp\n",
    "    max_lr = 0.01 # currently best for foot pp\n",
    "    base_lr = 1e-6 # 1e-6 1e-7\n",
    "    \n",
    "#     step_size = 25 # currently best for foot pp\n",
    "#     max_lr = 0.01 # currently best for foot pp\n",
    "#     base_lr = 1e-8 # 1e-6 1e-7\n",
    "\n",
    "    # warm up\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 100\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.5\n",
    "\n",
    "    iterations = epoch\n",
    "    cycle = np.floor(1+iterations/(2*step_size))# 1~20 range.\n",
    "    x = np.abs(iterations/step_size - 2*cycle + 1) # 1~0,repeat 20 cycle.\n",
    "    lr = base_lr + (max_lr-base_lr)*np.maximum(0, (1-x))\n",
    "\n",
    "    \n",
    "    #todo: boost the lr at initial setps.\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else max_lr\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else boost_lr\n",
    "#     lr = initial_lr(epoch)\n",
    "    #todo: boost the lr at fist step_size.\n",
    "    \n",
    "    # warm up\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = base_lr + (((max_lr - base_lr) / lr_ramp_ep) * epoch)\n",
    "    \n",
    "#     # decay\n",
    "#     if epoch > lr_ramp_ep:\n",
    "    decay = ((epoch+1)/ep_num)\n",
    "    base_part = 1.001 #1.1\n",
    "#         lr = lr * (base_part-decay)\n",
    "\n",
    "    return lr * (base_part-decay) * lr_decay # supressed the lr! in fact, it will reduce new lr to 1/2 ratio.\n",
    "\n",
    "\n",
    "rng = [i for i in range(ep_num)]\n",
    "y = [clr3(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.999999999999993e-08 ~ 0.00891990901   # original lr with epoch decay.\n",
    "# 2.4999999999999966e-08 ~ 0.004459954505 # supressed the lr!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze for finetune the toe model  \n",
    "unfreeze_model(model_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=100), #patience=step_size or ep_num\n",
    "#     lr_reduceonplateau,\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),#lrdump, decay or lrfn or lrfn2. clr\n",
    "    PrintLRheel()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model on all data\n",
    "history_heel_finetune = model_heel.fit(train_ds_pre_heel_s, \n",
    "                      verbose=1, \n",
    "                      epochs=ep_num_lr_search, \n",
    "                      validation_data=valid_ds_pre_heel_s, \n",
    "                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vis log(lr)\n",
    "#  a list of loss or lr, no index.\n",
    "# history_toe.history['val_loss']\n",
    "# history_toe.history['lr']\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_heel_finetune.history['lr'], history_heel_finetune.history['val_loss'])\n",
    "plt.xscale('log')\n",
    "plt.title('Search lr_max @FT')\n",
    "\n",
    "plt.ylabel('val_loss'), plt.ylim(0,50)\n",
    "plt.xlabel('lr (log)')\n",
    "plt.legend(['loss@lr'], loc='upper right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heel ft lr 1e-4 ~1e-3 will be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(history_heel_finetune.history['loss'])\n",
    "plt.plot(history_heel_finetune.history['val_loss'])\n",
    "plt.title('model ed loss')\n",
    "plt.ylabel('ed loss'), plt.ylim(3, 20)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}_heel_ft.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "\n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('model ed loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color), ax1.set_ylim(3, 50)\n",
    "\n",
    "ax1.plot(history_heel_finetune.history['loss'])\n",
    "ax1.plot(history_heel_finetune.history['val_loss'])\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_heel_finetune.history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "def get_valloss(his_v_l):   \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_heel_finetune.history['val_loss'])\n",
    "plt.savefig(f'{log_dir_name}_heel_ft_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valloss(his_v_l):\n",
    "     \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "vl, ep = get_valloss(history_heel_finetune.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl, ep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_valloss(his_v_l):\n",
    "     \n",
    "    print(f'val_loss: {np.min(his_v_l)} at epoch {np.argmin(his_v_l)}.')\n",
    "    \n",
    "print_valloss(history_heel_finetune.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean ed-loss == mean ed of test data.\n",
    "model_heel.evaluate(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # inference all val_ds\n",
    "# predictions = model.predict(valid_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # inference bs by bs of val_ds #model.predict()#一次做完即可不用分batch\n",
    "# image_batch, label_batch = valid_ds_pre_heel_s.as_numpy_iterator().next()\n",
    "# pred = model.predict_on_batch(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_ds一次做完即可不用分batch\n",
    "# neg = label_batch - pred\n",
    "# neg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg.mean()#所有x,y平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg.mean(axis=0)#所有x 所有y個別平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg.mean(axis=1)#左x右y相加的平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.median(neg)#中位數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show pp pred\n",
    "\n",
    "* we can switch toe/hell by comment it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Simple2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)\n",
    "# # it_valid_ds_pre_heel_s = iter(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # image_batch, label_batch = next(valid_ds_pre_toe_s)\n",
    "\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "# # image_batch, label_batch = next(it_valid_ds_pre_heel_s)\n",
    "\n",
    "\n",
    "# # pred = model_toe.predict_on_batch(image_batch) #predictions\n",
    "# pred = model.predict_on_batch(image_batch) #Simple 2D CNN model predictions\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# for i in range(64):\n",
    "#     ax = plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(image_batch[i])\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     # note: y_offset_toe for ds image\n",
    "    \n",
    "#     #ground truth\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=15, mew=4)\n",
    "\n",
    "#     #pred\n",
    "#     plt.plot(pred[i][0], pred[i][1], 'k+', markersize=15, mew=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFN Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)\n",
    "# it_valid_ds_pre_heel_s = iter(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# image_batch, label_batch = next(valid_ds_pre_toe_s)\n",
    "\n",
    "image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_heel_s)\n",
    "\n",
    "\n",
    "pred = model_toe.predict_on_batch(image_batch) #predictions\n",
    "# pred = model.predict_on_batch(image_batch) #Simple 2D CNN model predictions\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(64):\n",
    "    ax = plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.title(label_batch[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # note: y_offset_toe for ds image\n",
    "    \n",
    "    #ground truth\n",
    "    plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=15, mew=2)\n",
    "\n",
    "    #pred\n",
    "    plt.plot(pred[i][0], pred[i][1], 'k+', markersize=15, mew=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds一次做完即可不用分batch\n",
    "neg = label_batch - pred\n",
    "neg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(neg)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_abs = np.abs(neg)\n",
    "neg_abs.mean(axis=0)#所有x 所有y個別平均  neg.mean(axis=0)#所有x 所有y個別平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ED 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = neg_abs.mean(axis=0)\n",
    "ed_metric_2d([0,0], [neg_abs.mean(axis=0)]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFN Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)\n",
    "it_valid_ds_pre_heel_s = iter(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# image_batch, label_batch = next(valid_ds_pre_toe_s)\n",
    "\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "image_batch, label_batch = next(it_valid_ds_pre_heel_s)\n",
    "\n",
    "\n",
    "pred = model_heel.predict_on_batch(image_batch) #predictions\n",
    "# pred = model.predict_on_batch(image_batch) #Simple 2D CNN model predictions\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(64):\n",
    "    ax = plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.title(label_batch[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # note: y_offset_toe for ds image\n",
    "    \n",
    "    #ground truth\n",
    "    plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=15, mew=2)\n",
    "\n",
    "    #pred\n",
    "    plt.plot(pred[i][0], pred[i][1], 'k+', markersize=15, mew=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds一次做完即可不用分batch\n",
    "neg = label_batch - pred\n",
    "neg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(neg)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_abs = np.abs(neg)\n",
    "neg_abs.mean(axis=0)#所有x 所有y個別平均  neg.mean(axis=0)#所有x 所有y個別平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ED 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = neg_abs.mean(axis=0)\n",
    "ed_metric_2d([0,0], [neg_abs.mean(axis=0)]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merg Toe/Heel model and predict the Test data at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TEST DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 'test_submission.csv'\n",
    "df_ts = pd.read_csv(ts)\n",
    "df_ts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe\n",
    "list_ds_test = tf.data.Dataset.from_tensor_slices(df_ts['images'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds_test)#.shape() #take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check The type specification of an element of this dataset.\n",
    "list_ds_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds_test.take(5):\n",
    "    print(f'take test sample: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DS: Process TEST path to image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST-DS: re-used from train/val-ds\n",
    "\n",
    "im_test = 'test_images/'\n",
    "\n",
    "'''\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    boolen = parts[-2] == class_names\n",
    "    #one_hot_num = np.array(boolen, dtype=np.int) not works should use tf.x repalced.\n",
    "    one_hot_num = tf.dtypes.cast(boolen, tf.int64)\n",
    "    one_num = tf.argmax(one_hot_num)\n",
    "    print('one_num:', one_num)\n",
    "    # Integer encode the label\n",
    "    return one_num\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])# augment 已經resize過一次了 但這邊不先做會比較慢\n",
    "    return tf.cast(tf.image.resize(img, [img_height, img_width]), tf.uint8)# 避免float over at augment\n",
    "'''\n",
    "\n",
    "#\n",
    "# map list to ds, Toe part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_toe_test(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y1=y_offset_toe;    x1=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_toe_test(file_name):\n",
    "    file_path = im_test + file_name\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_toe_test(img)\n",
    "    return img, file_name\n",
    "\n",
    "#\n",
    "# map list to ds, Heel part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_heel_test(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y2=y_offset_heel;    x2=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y2), int(x2), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_heel_test(file_name):\n",
    "    file_path = im_test + file_name\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_heel_test(img)\n",
    "    return img, file_name\n",
    "\n",
    "\n",
    "#\n",
    "# test how to put parameters to map\n",
    "#\n",
    "\n",
    "def t_ds_map(file_path,x1,y1,x2,y2):\n",
    "#     img = get_img('train/images/' + str(file_path))\n",
    "#     print(file_path)\n",
    "    return file_path,x1,y1,x2,y2 #img, [x1,y1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Toe ds\n",
    "test_ds_map_toe = list_ds_test.map(process_path_toe_test, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# TEST Heel ds\n",
    "test_ds_map_heel = list_ds_test.map(process_path_heel_test, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, file_name in test_ds_map_toe.take(5):\n",
    "    print(f'take sample: {img.shape} {file_name}')\n",
    "    \n",
    "# print('f', f.dtype)\n",
    "# print('xy', xy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare TEST_ds_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance_cache_test(ds, cache=True):\n",
    "\n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "#     if augment:\n",
    "# #         ds = ds.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(AA, num_parallel_calls=AUTOTUNE)\n",
    "# #         ds = ds.map(RA, num_parallel_calls=AUTOTUNE)\n",
    "#         print(\"Check augment :Y\", augment)\n",
    "#     else:\n",
    "#         print(\"Check augment :N\", augment)\n",
    "    \n",
    "#     #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "#     ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "#     ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=False) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(1000)# 1k for foot test images #MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "\"\"\"\n",
    "# TEST Toe ds_pre\n",
    "test_ds_pre_toe = configure_for_performance_cache_test(test_ds_map_toe)\n",
    "\n",
    "# TEST Heel ds_pre\n",
    "test_ds_pre_heel = configure_for_performance_cache_test(test_ds_map_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test (abandon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # inference all test_ds once\n",
    "# predictions_toe = model_toe.predict(test_ds_pre_toe)\n",
    "# predictions_toe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions_toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_toe[:,1] = predictions_toe[:,1] + y_offset_toe\n",
    "# predictions_toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # inference all test_ds once\n",
    "# predictions_heel = model_heel.predict(test_ds_pre_heel)\n",
    "# predictions_heel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_heel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_heel[:,1] = predictions_heel[:,1] + y_offset_heel\n",
    "# predictions_heel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge toe/hell pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_th = np.append(predictions_toe, predictions_heel, axis=1)#左右接\n",
    "# predictions_th.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_th.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_name = np.expand_dims(df_ts['images'], axis=1)\n",
    "# images_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_merge = np.append(images_name, predictions_th, axis=1)#左右接\n",
    "# predictions_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_merge.take(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame(predictions_merge)\n",
    "# df_submission.columns = ['images','x1','y1','x2','y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if models are in last time frame\n",
    "best_model_toe_name = get_best_model_name('toe')\n",
    "best_model_heel_name = get_best_model_name('heel')\n",
    "\n",
    "# # if toe/heel are in different time frame\n",
    "# best_model_toe_name = '20210118-212454/toe_EfficientNetB0_bs64_w120_best_val_loss.h5'#6.3318 @e393\n",
    "# best_model_heel_name = '20210122-084854/heel_EfficientNetB0_bs64_w120_best_val_loss.h5'#3.27979@152\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(best_model_toe_name)\n",
    "print(best_model_heel_name)\n",
    "# log_dir_name + '/' + 'leaf-2020-12-01-EfficientNetB7_top-layer50_lr_lrfn_val-acc.8352_wh512_e37.h5'\n",
    "\n",
    "best_model_toe = tf.keras.models.load_model(best_model_toe_name,compile=False)\n",
    "best_model_heel = tf.keras.models.load_model(best_model_heel_name,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model separately afterwards. to load model with custom loss function\n",
    "\n",
    "* https://github.com/tensorflow/tensorflow/issues/32348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_toe.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "                loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "                #metrics=['mae', 'accuracy'])\n",
    "best_model_heel.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "                loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "                #metrics=['mae', 'accuracy'])\n",
    "\n",
    "# best_model_toe.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=tf.keras.losses.MeanSquaredError())#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "# best_model_heel.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=tf.keras.losses.MeanSquaredError())#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# inference all test_ds once\n",
    "predictions_toe = best_model_toe.predict(test_ds_pre_toe)\n",
    "predictions_toe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_toe[:,1] = predictions_toe[:,1] + y_offset_toe\n",
    "\n",
    "# for [0,1]\n",
    "# predictions_toe[:,0] = predictions_toe[:,0]*120\n",
    "# predictions_toe[:,1] = predictions_toe[:,1]*120 + y_offset_toe\n",
    "\n",
    "# # for [-1,1]\n",
    "# # for re-scale back xy \n",
    "# # return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "# # return img, [(x2-60)/60,((y2-y_offset_heel)-60)/60]#normalized [-1,1] \n",
    "# predictions_toe[:,0] = (predictions_toe[:,0]*60)+60\n",
    "# predictions_toe[:,1] = (predictions_toe[:,1]*60)+60 + y_offset_toe\n",
    "\n",
    "predictions_toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# inference all test_ds once\n",
    "predictions_heel = best_model_heel.predict(test_ds_pre_heel)\n",
    "predictions_heel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_heel[:,1] = predictions_heel[:,1] + y_offset_heel\n",
    "\n",
    "# for [0,1]\n",
    "# predictions_heel[:,0] = predictions_heel[:,0]*120\n",
    "# predictions_heel[:,1] = predictions_heel[:,1]*120 + y_offset_heel\n",
    "\n",
    "# # for [-1,1]\n",
    "# predictions_heel[:,0] = (predictions_heel[:,0]*60)+60\n",
    "# predictions_heel[:,1] = (predictions_heel[:,1]*60)+60 + y_offset_heel\n",
    "\n",
    "predictions_heel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge toe/hell pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_th = np.append(predictions_toe, predictions_heel, axis=1)#左右接\n",
    "predictions_th.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name = np.expand_dims(df_ts['images'], axis=1)\n",
    "images_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_merge = np.append(images_name, predictions_th, axis=1)#左右接\n",
    "predictions_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(predictions_merge)\n",
    "df_submission.columns = ['images','x1','y1','x2','y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submi_name = '0000_ft_' + log_dir_name +'.csv'\n",
    "# submi_name = 'Bth_clr3_2690_XYnorm[0-1]_' + log_dir_name +'.csv'\n",
    "df_submission.to_csv(submi_name, index=False)\n",
    "print('Save {} as submission CSV.'.format(submi_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bth_clr3_2690_ed_findtune_20210202-141718.csv\n",
    "\n",
    "#toe.9.9/heel.4.4 109 trainable LB:9.3411759 比heel保持top-20略高0.04 (9.3084957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ED sum\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "t_vl, _ = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "h_vl, _ = get_valloss(history_heel_finetune.history['val_loss'])\n",
    "\n",
    "print(f'{round(t_vl,5)} + {round(h_vl,5)} = {round(t_vl + h_vl,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# best_model_name = './cop_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_e' + str(ep_num) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_.h5'\n",
    "# # model.save(best_model_name)\n",
    "# print(\"Save model: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "multi output model:\n",
    "https://navoshta.com/end-to-end-deep-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
