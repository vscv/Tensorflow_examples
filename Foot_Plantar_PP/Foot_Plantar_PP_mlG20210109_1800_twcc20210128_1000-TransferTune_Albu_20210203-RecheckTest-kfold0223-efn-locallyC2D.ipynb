{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# efn B0 + locally connected 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 Course of transfer learning and Fine tune 2021-01-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [How-to] 1. k-fold for cross validation\n",
    "\n",
    "#### Create a simple k-fold for train classification model.\n",
    "\n",
    "* In this short course you learned:\n",
    "\n",
    "* data pipline\n",
    "\n",
    "* transfer learning\n",
    "\n",
    "* fine tune\n",
    "\n",
    "* callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: move to note.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.style.use(\"bmh\")\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import errno\n",
    "\n",
    "# albumentations\n",
    "from functools import partial\n",
    "# from albumentations import (\n",
    "#     Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n",
    "#     Rotate\n",
    "# )\n",
    "import albumentations as A\n",
    "\n",
    "# from adabelief_tf import AdaBeliefOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "\n",
    "t_timer = TicToc() #create instance of class\n",
    "\n",
    "t_timer.tic() #Start timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LC2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efnetB0_LC2D_LSW_2021_02_27 as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等於true, pred點位ed的平均，LB評分方式。(toe/heel即p1,p2要個別算ed一次再相加)\n",
    "def ed_metric_2d_mean(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_trainOrNot_layers(model, printlayers=False):\n",
    "    tt = 0\n",
    "    nt = 0\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            tt +=1\n",
    "            if printlayers:\n",
    "                print(f'{layer.name}')\n",
    "        else:\n",
    "            nt +=1\n",
    "    print('\\n*********************************** Start fine tune ***********************************')\n",
    "    print(f'tt: {tt}, nt:{nt}, total layers:{tt+nt}')\n",
    "    print('*********************************** Start fine tune ***********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"efnB0LSW\"\n",
    "\n",
    "# Transfer learning from pre-trained weights\n",
    "def build_efn_model(outputnum, top_dropout_rate, drop_connect_rate):\n",
    "#     base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(120,120,3),drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=(120,120,3),drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    base_model.trainable = False\n",
    "    print(\"base_model.trainable : \", base_model.trainable)\n",
    "\n",
    "    # Rebuild top\n",
    "    gap2d = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    BNL = tf.keras.layers.BatchNormalization()(gap2d) #tood: remove#\n",
    "    dropout = tf.keras.layers.Dropout(top_dropout_rate)(BNL)#tood: remove# J add dropout, for flood 0.2 is ok. for leaf 0.4 is better.\n",
    "    outputs = tf.keras.layers.Dense(outputnum)(dropout)# remove activation for regression output (to default, the linear), , activation = 'relu' no help\n",
    "\n",
    "    # Compile new model\n",
    "    model = tf.keras.Model(base_model.input, outputs, name=model_name)\n",
    "\n",
    "\n",
    "#     # unfreeze the top #fine_tune_at# layers while leaving BatchNorm layers frozen\n",
    "#     fine_tune_at = 20 #10 #241 #20\n",
    "#     print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "#     for layer in model_toe.layers[-fine_tune_at:]:\n",
    "#         if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top_dropout_rate = 0.8 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "drop_connect_rate = 0.9 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "outputnum = 2\n",
    "# with strategy.scope():\n",
    "model_toe = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "B0\n",
    "Total params: 4,057,253\n",
    "Trainable params: 5,122\n",
    "Non-trainable params: 4,052,131\n",
    "\n",
    "\n",
    "B0 LC2DLSW\n",
    "Total params: 54,853,541\n",
    "Trainable params: 5,122\n",
    "Non-trainable params: 54,848,419\n",
    "\n",
    "tt: 4, nt:49, total layers:53\n",
    "Total params: 8,698,843\n",
    "Trainable params: 5,122\n",
    "Non-trainable params: 8,693,721\n",
    "\n",
    "\n",
    "tt: 4, nt:162, total layers:166\n",
    "Total params: 13,417,099\n",
    "Trainable params: 5,122\n",
    "Non-trainable params: 13,411,977\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_toe, to_file='model_toe_conv_layer_blocks_LC2DLSW.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model_toe_conv_layer_blocks_LC2DLSW.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape=(120,120,3), num_classes=2):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "#     x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "#         residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")( # ok but toe ed 5.8\n",
    "        residual = tf.keras.layers.LocallyConnected2D(size, 1, strides=2, padding=\"valid\")( ## LocallyConnected2D not work halt from stating training.\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#     if num_classes == 2:\n",
    "#         activation = \"sigmoid\"\n",
    "#         units = 1\n",
    "#     else:\n",
    "#         activation = \"softmax\"\n",
    "#         units = num_classes\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "#     outputs = layers.Dense(units, activation=activation)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_toe = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model_trainOrNot_layers(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image size, Batch size, toe/heel-offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # 16 #32 #64 #128 #32 #64 #todo: reduce the BS maybe help to reduce the loss\n",
    "img_height = 120 #512 #224 #100\n",
    "img_width = 120 #512 #224 #100\n",
    "\n",
    "y_offset_toe = 80\n",
    "y_offset_heel = 280 #400-120=280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf MirroredStrategy seting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf MirroredStrategy seting\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print('\\nNumber of REPLICAS: {}\\n'.format(REPLICAS))\n",
    "\n",
    "\n",
    "MULTI_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "print('BATCH_SIZE: {}, MULTI_BATCH_SIZE: {}'.format(BATCH_SIZE, MULTI_BATCH_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動調節tf.data管道\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the training dataset W/ croped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load samples as data-farame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # data-org #\n",
    "# ann = 'annotation_1424_merge.csv'\n",
    "# im_p = 'train/images/'\n",
    "# CSVNAME = \"\"\n",
    "\n",
    "\n",
    "# # data-org-augm#\n",
    "# ann = 'annotation_2848_augm.csv'\n",
    "# im_p = 'train_augm/images/'\n",
    "# CSVNAME = \"\"\n",
    "\n",
    "\n",
    "# data-train # # current best dataset.1424-79.\n",
    "ann = 'annotation_1345_good.csv'\n",
    "im_p = 'train/images/'\n",
    "CSVNAME = \"K1345\"\n",
    "\n",
    "# data-augm #\n",
    "# ann = 'annotation_2690_augm.csv'\n",
    "# im_p = 'train_augm/images/'\n",
    "# CSVNAME = \"\"\n",
    "\n",
    "\n",
    "# # data-train-HPL-1123\n",
    "# ann = 'annotation_1123_HPL_Good.csv'\n",
    "# im_p = 'train/images/'\n",
    "# CSVNAME = \"\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(ann)\n",
    "df[1120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, the image_####.jpg now are random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tf.dataset (DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe\n",
    "list_ds = tf.data.Dataset.from_tensor_slices((df['images'], df['x1'], df['y1'], df['x2'], df['y2']))\n",
    "# list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds)#.shape() #take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check The type specification of an element of this dataset.\n",
    "list_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,x1,y1,x2,y2 in list_ds.take(5):\n",
    "    print(f'take sample: {f} {x1} {y1} {x2} {y2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np decode to UTF-8\n",
    "print(f.numpy().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ds iterator for consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python iterator\n",
    "\n",
    "it_list_ds = iter(list_ds) # Make sure iter ds only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using iter and consuming its elements using next: every print different image name.\n",
    "\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = next(it_list_ds)\n",
    "    print(image.numpy(), x1.numpy(), y1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = valid_ds_pre_s.as_numpy_iterator().next()\n",
    "# pred = model.predict_on_batch(image_batch)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = list_ds.as_numpy_iterator().next()# every time create a new iter, so need put iter out of above cell.\n",
    "    print(image, x1, y1, x2, y2)\n",
    "    \n",
    "iter_test_list = list_ds.as_numpy_iterator()\n",
    "print(\"===== Create iterator once and pull out to above cell. =====\")\n",
    "for i in range(4):\n",
    "    image, x1, y1, x2, y2 = iter_test_list.next()\n",
    "    print(image, x1, y1, x2, y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process path to image tensor in DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    boolen = parts[-2] == class_names\n",
    "    #one_hot_num = np.array(boolen, dtype=np.int) not works should use tf.x repalced.\n",
    "    one_hot_num = tf.dtypes.cast(boolen, tf.int64)\n",
    "    one_num = tf.argmax(one_hot_num)\n",
    "    print('one_num:', one_num)\n",
    "    # Integer encode the label\n",
    "    return one_num\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])# augment 已經resize過一次了 但這邊不先做會比較慢\n",
    "    return tf.cast(tf.image.resize(img, [img_height, img_width]), tf.uint8)# 避免float over at augment\n",
    "'''\n",
    "\n",
    "#\n",
    "# map list to ds, Toe part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_toe(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y1=y_offset_toe;    x1=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_toe(file_path,x1,y1,x2,y2):\n",
    "    file_path = im_p + file_path\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_toe(img)\n",
    "    return img, [x1,y1-y_offset_toe]#Original [0,120]\n",
    "    #return img, x1, y1-y_offset_toe #Original [0,120] #貌似ed不用改，蛋mse變超大\n",
    "    #return img, [x1/120,(y1-y_offset_toe)/120]#normalized [0,1] xy <dtype: 'float64'>, no help.\n",
    "    #return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] , no help.\n",
    "\n",
    "#\n",
    "# map list to ds, Heel part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_heel(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y2=y_offset_heel;    x2=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y2), int(x2), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_heel(file_path,x1,y1,x2,y2):\n",
    "    file_path = im_p + file_path\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_heel(img)\n",
    "    return img, [x2,y2-y_offset_heel]#Original [0,120]\n",
    "    #return img, x2, y2-y_offset_heel #Original [0,120] #貌似ed不用改，蛋mse變超大\n",
    "    #return img, [x2/120,(y2-y_offset_heel)/120]#normalized [0,1] xy <dtype: 'float64'>, no help.\n",
    "    #return img, [(x2-60)/60,((y2-y_offset_heel)-60)/60]#normalized [-1,1] , no help.\n",
    "\n",
    "#\n",
    "# test how to put parameters to map\n",
    "#\n",
    "\n",
    "def t_ds_map(file_path,x1,y1,x2,y2):\n",
    "#     img = get_img('train/images/' + str(file_path))\n",
    "#     print(file_path)\n",
    "    return file_path,x1,y1,x2,y2 #img, [x1,y1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toe ds\n",
    "train_ds_map_toe = list_ds.map(process_path_toe, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Heel ds\n",
    "train_ds_map_heel = list_ds.map(process_path_heel, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, xy in train_ds_map_toe.take(1):\n",
    "#     print(f'take sample: {xy}')\n",
    "    \n",
    "# print('f', f.dtype)\n",
    "# print('xy', xy.dtype)\n",
    "\n",
    "# for img, x, y in train_ds_map_toe.take(1):\n",
    "#     print(f'take sample: {x} {y}')\n",
    "    \n",
    "# print('img', img.dtype)\n",
    "# print('x', x.dtype)\n",
    "# x\n",
    "\n",
    "for img, [x, y] in train_ds_map_toe.take(1):\n",
    "    print(f'take sample: {x} {y}')\n",
    "    \n",
    "print('f', f.dtype)\n",
    "print('x', x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f,x1,y1,x2,y2 in train_ds_map.take(5):\n",
    "#     print(f'take sample: {f} {x1} {y1} {x2} {y2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [new] Split train_ds_pre with ratio of validation %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ToDo 20210201] keep orignal validation in 0.1, but augmenting train_ds in input layer or in the tf.ds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2021-02-23] New k-split ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split Toe\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_map_toe).numpy() * 0.2)\n",
    "# # val_size = int(tf.data.experimental.cardinality(train_ds_map_toe).numpy() * 0.1)#no help\n",
    "\n",
    "# train_ds_map_toe_s = train_ds_map_toe.skip(val_size)\n",
    "# valid_ds_map_toe_s = train_ds_map_toe.take(val_size)\n",
    "\n",
    "# print(f'whole samples = {len(train_ds_map_toe)}')\n",
    "# print(f'val_size = {val_size}')\n",
    "\n",
    "# print('ds_train = ', tf.data.experimental.cardinality(train_ds_map_toe_s).numpy())\n",
    "# print('ds_valid = ', tf.data.experimental.cardinality(valid_ds_map_toe_s).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # split Heel\n",
    "# val_size = int(tf.data.experimental.cardinality(train_ds_map_heel).numpy() * 0.2)\n",
    "# # val_size = int(tf.data.experimental.cardinality(train_ds_map_heel).numpy() * 0.1)\n",
    "\n",
    "\n",
    "# train_ds_map_heel_s = train_ds_map_heel.skip(val_size)\n",
    "# valid_ds_map_heel_s = train_ds_map_heel.take(val_size)\n",
    "\n",
    "# print(len(train_ds_map_heel))\n",
    "# print(val_size)\n",
    "# print(tf.data.experimental.cardinality(train_ds_map_heel_s).numpy())\n",
    "# print(tf.data.experimental.cardinality(valid_ds_map_heel_s).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing cell\n",
    "# kf = []\n",
    "# for k in range(5):\n",
    "#     kf.append(train_ds_map_heel.shard(num_shards=5, index=k))\n",
    "#     print(\"k =\", k,\"num=\", tf.data.experimental.cardinality(kf[k]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for img, [x,y] in kf[1].take(1):\n",
    "#     print(f'take sample: {x} {y}')\n",
    "    \n",
    "# print('img', img.dtype)\n",
    "# print('x', x.dtype)\n",
    "# print('y', y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing cell\n",
    "\n",
    "# range_k_0 = train_ds_map_heel.window(5)\n",
    "\n",
    "# print(len(range_k_0))\n",
    "# print(tf.data.experimental.cardinality(range_k_0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing cell\n",
    "\n",
    "# def get_train_valid_k_split():\n",
    "#     x = tf.data.Dataset.range(1000)\n",
    "#     val_size = int(tf.data.experimental.cardinality(x).numpy() * 0.2)\n",
    "    \n",
    "#     for k in range(5):\n",
    "#         train_num = x.take(val_size + k*val_size)\n",
    "#         valid_num = x.skip(k*val_size)\n",
    "        \n",
    "#         print(\"k=\", k)\n",
    "#         print(tf.data.experimental.cardinality(train_num).numpy())\n",
    "#         print(tf.data.experimental.cardinality(valid_num).numpy())\n",
    "    \n",
    "    \n",
    "# get_train_valid_k_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing cell\n",
    "\n",
    "# \n",
    "# tf.slice\n",
    "# tf.data.experimental.choose_from_datasets\n",
    "\n",
    "\n",
    "# x = list_ds\n",
    "# val_size = int(tf.data.experimental.cardinality(list_ds).numpy() * 0.2)\n",
    "x = tf.data.Dataset.range(10)\n",
    "\n",
    "def check_KFold_ds(x, K=5):\n",
    "    \n",
    "    val_size = int(tf.data.experimental.cardinality(x).numpy() * 0.2)\n",
    "    print(\"val_size=\", val_size)\n",
    "    \n",
    "    for k in range(K):\n",
    "#         k_train = x.take(val_size + k*val_size)\n",
    "#         k_valid = x.skip(k*val_size)\n",
    "#         k_train = tf.slice(x, k*val_size, val_size) #only for pure tensors not \n",
    "#         k_valid = x.skip(k*val_size)\n",
    "\n",
    "        # may skip twicce to performe kflod\n",
    "        t_take = x.take(k*val_size)\n",
    "        t_skip = x.skip(k*val_size+val_size)\n",
    "        k_train = t_take.concatenate(t_skip)\n",
    "        \n",
    "        v_skip = x.skip(k*val_size)\n",
    "        k_valid = v_skip.take(val_size)\n",
    "\n",
    "        print(\"k =\", k,\"k*val_size+val_size\", k*val_size+val_size, \"k_train num=\", tf.data.experimental.cardinality(k_train).numpy())\n",
    "\n",
    "\n",
    "        # x = tf.data.Dataset.range(10)\n",
    "#         for n in k_train:\n",
    "#             print(n.numpy())\n",
    "#         for n in k_valid:\n",
    "#             print(n.numpy())\n",
    "        \n",
    "        # list_ds\n",
    "#         for img, x1, y1, x2, y2 in k_train:\n",
    "#             print(x1, y1)\n",
    "\n",
    "        # train_ds_map_toe\n",
    "#         for img, (x, y) in k_train:\n",
    "#             print(x.numpy(), y.numpy())\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "check_KFold_ds(x)\n",
    "# check_KFold_ds(list_ds)    \n",
    "# check_KFold_ds(train_ds_map_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.data.Dataset.range(10)\n",
    "# val_size = int(tf.data.experimental.cardinality(x).numpy() * 0.2)\n",
    "# print(\"val_size=\", val_size)\n",
    "\n",
    "def get_KFold_ds(x, K=0):\n",
    "        \n",
    "    k = K\n",
    "    # may skip twicce to perform kflod\n",
    "    # train ds\n",
    "    t_take = x.take(k*val_size)\n",
    "    t_skip = x.skip(k*val_size+val_size)\n",
    "    k_train = t_take.concatenate(t_skip)\n",
    "    # val ds\n",
    "    v_skip = x.skip(k*val_size)\n",
    "    k_valid = v_skip.take(val_size)\n",
    "\n",
    "    return k_train, k_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(tf.data.experimental.cardinality(train_ds_map_toe).numpy() * 0.2)\n",
    "t, v = get_KFold_ds(train_ds_map_toe, 1)\n",
    "\n",
    "print(tf.data.experimental.cardinality(t).numpy())\n",
    "print(tf.data.experimental.cardinality(v).numpy())\n",
    "\n",
    "# for n in v:\n",
    "#     print(n.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_map_toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albumentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # for NO keypoint augment\n",
    "# transforms = A.Compose([\n",
    "# #             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=65, quality_upper=100, p=0.5),#A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5)\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "# #             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA(alpha=0.1, always_apply=False, p=1),#A.FancyPCA(alpha=0.1, always_apply=False, p=0.5)\n",
    "#             A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5), #0.8~0.99 may better\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE(clip_limit=(1, 8), tile_grid_size=(8, 8), always_apply=False, p=0.5), #A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)\n",
    "# #             A.GlassBlur(sigma=0.9, max_delta=2, iterations=2, always_apply=False, mode='fast', p=0.5),\n",
    "# #             A.GaussNoise(var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5),\n",
    "# #             A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=0.5),\n",
    "# #             A.HorizontalFlip(),\n",
    "    \n",
    "#             # try other augm, seems to strong...\n",
    "#             A.RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
    "#             A.Equalize(always_apply=False, p=0.5, mode='cv', by_channels=True),\n",
    "#             A.MultiplicativeNoise(always_apply=False, p=0.5, multiplier=(0.8, 1.5), per_channel=False, elementwise=False),\n",
    "#             A.RandomFog(always_apply=False, p=0.5, fog_coef_lower=0.2, fog_coef_upper=0.3, alpha_coef=0.25),\n",
    "\n",
    "# ])\n",
    "\n",
    "\n",
    "# def aug_fn(image, img_size):\n",
    "#     data = {\"image\":image}\n",
    "#     aug_data = transforms(**data)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "# #     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "#     aug_img = tf.cast(aug_img, tf.float32)\n",
    "#     aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "#     return aug_img\n",
    "\n",
    "# def process_data(image, label, img_size):\n",
    "#     aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "#     return aug_img, label\n",
    "\n",
    "# def set_shapes(img, label, img_shape=(120,120,3)):\n",
    "#     img.set_shape(img_shape)\n",
    "# #     label.set_shape([]) # commited for go around error\n",
    "#     return img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for NO keypoint augment AND for OneOf[] for better heel loss.\n",
    "# transforms_oneof = A.Compose(A.OneOf([\n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "#             A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "#             A.GlassBlur(sigma=0.9, max_delta=2, iterations=2, always_apply=False, mode='fast', p=0.5),\n",
    "#             A.GaussNoise(var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5),\n",
    "#             A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=.5)\n",
    "# #             A.HorizontalFlip(),\n",
    "#             ]),p=0.5)\n",
    "\n",
    "\n",
    "# def aug_fn_oneof(image, img_size):\n",
    "#     data = {\"image\":image}\n",
    "#     aug_data = transforms_oneof(**data)\n",
    "#     aug_img = aug_data[\"image\"]\n",
    "# #     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "#     aug_img = tf.cast(aug_img, tf.float32)\n",
    "#     aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "#     return aug_img\n",
    "\n",
    "# def process_data_oneof(image, label, img_size):\n",
    "#     aug_img = tf.numpy_function(func=aug_fn_oneof, inp=[image, img_size], Tout=tf.float32)\n",
    "#     return aug_img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Testing keypoints augment\n",
    "# transforms = A.Compose([\n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA (alpha=0.1, always_apply=False, p=1),\n",
    "#             A.Downscale (scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             ]\n",
    "#             , \n",
    "#             keypoint_params=A.KeypointParams(format='xy'),  #currently not works for tf.ds yet.\n",
    "#             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing keypoints augment\n",
    "transforms = A.Compose([\n",
    "            A.RandomBrightness(limit=0.1, p=0.5),\n",
    "            A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "            A.RandomContrast(limit=0.2, p=0.5),\n",
    "            A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "            A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "    \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomResizedCrop(always_apply=False, height=120, width=120, scale=(0.9, 0.99), ratio=(1.0, 1.0), interpolation=0, p=0.5),#xy become double need change dtype of label. # pp will outside the image.\n",
    "            A.IAAAffine(scale=0.9, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', always_apply=False, p=0.5),\n",
    "#             A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0.06, 0.06), scale_limit=(-0.1, 0.1), rotate_limit=(-5, 5), interpolation=1, border_mode=2, value=(0, 0, 0), mask_value=None),\n",
    "    #2021-02-26\n",
    "#             A.IAAPerspective(scale=(0.05, 0.1), keep_size=True, always_apply=False, p=0.5),#fallout image make train stop. NOT support keypoints!!!!!\n",
    "            ]\n",
    "            , \n",
    "            keypoint_params=A.KeypointParams(format='xy',remove_invisible=True),  #currently not works for tf.ds yet.\n",
    "            )\n",
    "\n",
    "# Testing keypoints augment\n",
    "# @tf.function\n",
    "def aug_fn(image, keypoints, img_size):\n",
    "#     print('Check keypoints aug_fun 00:', keypoints) # Check keypoints aug_fun 00: [[53 58]]\n",
    "#     data = {\"image\":image}\n",
    "    aug_data = transforms(image=image, keypoints=keypoints)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_xy  = aug_data[\"keypoints\"]\n",
    "#     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.cast(aug_img, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "    \n",
    "    aug_xy = tf.cast(aug_xy, tf.float32) #有些變形輸出是double\n",
    "#     print('Check aug_xy:', aug_xy) # Check aug_xy: [(95, 45)] #印到這邊都是對的\n",
    "    return aug_img, aug_xy \n",
    "\n",
    "# @tf.function\n",
    "def process_data(image, keypoints, img_size):\n",
    "    \n",
    "    print('Check keypoints process01:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "        \n",
    "#     keypoints = tf.make_ndarray(keypoints)\n",
    "#     keypoints = np.array(keypoints)\n",
    "#     keypoints = list(keypoints)\n",
    "#     keypoints = np.asarray(keypoints, dtype=np.float32)\n",
    "#     keypoints = tf.make_ndarray(keypoints.op.get_attr('value'))\n",
    "\n",
    "#     keypoints = tf.reshape(keypoints, [1, 2])\n",
    "    keypoints = tf.reshape(keypoints, [1, 2]) # for 'convert_keypoint_to_albumentations'\n",
    "#     keypoints = np.reshape(keypoints, (1, 2))#not support tensor with np.call.\n",
    "\n",
    "    print('Check keypoints process02:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "\n",
    "#     aug_img, aug_xy = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "#     aug_img, aug_xy = tf.py_function(func=aug_fn, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.int64])#for tensors.\n",
    "    aug_img, aug_xy = tf.numpy_function(func=aug_fn, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.float32])\n",
    "    print('Check keypoints process03:', aug_xy)\n",
    "    \n",
    "    aug_xy = tf.reshape(aug_xy, [2,]) # for 'tf ds tarining'\n",
    "    print('Check keypoints process04:', aug_xy)\n",
    "        \n",
    "    return aug_img, aug_xy \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###  for AToe ###\n",
    "# some pp will outside of image bcs p2 is close to 400.\n",
    "\n",
    "\n",
    "\n",
    "# Testing keypoints augment\n",
    "transforms_AToe = A.Compose([\n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "#             A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "#             A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "#             A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5),\n",
    "#             A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "#             A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "    \n",
    "#             A.RandomBrightness(limit=0.1, p=0.5),\n",
    "            A.JpegCompression(quality_lower=65, quality_upper=100, p=0.5),#A.JpegCompression(quality_lower=85, quality_upper=100, p=0.5)\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "#             A.RandomContrast(limit=0.2, p=0.5),\n",
    "            A.FancyPCA(alpha=0.1, always_apply=False, p=1),#A.FancyPCA(alpha=0.1, always_apply=False, p=0.5)\n",
    "            A.Downscale(scale_min=0.7, scale_max=0.9, interpolation=0, always_apply=False, p=0.5), #0.8~0.99 may better\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "            A.CLAHE(clip_limit=(1, 8), tile_grid_size=(8, 8), always_apply=False, p=0.5), #A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)\n",
    "    \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "#             A.RandomResizedCrop(always_apply=False, height=120, width=120, scale=(0.75, 0.9), ratio=(1.0, 1.0), interpolation=0, p=0.5),#xy become double need change dtype of label. # pp will outside the image.\n",
    "            A.IAAAffine (scale=0.9, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', always_apply=False, p=0.5),\n",
    "#             A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0.06, 0.06), scale_limit=(-0.1, 0.1), rotate_limit=(-5, 5), interpolation=1, border_mode=2, value=(0, 0, 0), mask_value=None),\n",
    "            ]\n",
    "            , \n",
    "            keypoint_params=A.KeypointParams(format='xy',remove_invisible=True),  #currently not works for tf.ds yet.\n",
    "            )\n",
    "\n",
    "\n",
    "# Testing keypoints augment\n",
    "# @tf.function\n",
    "def aug_fn_AToe(image, keypoints, img_size):\n",
    "#     print('Check keypoints aug_fun 00:', keypoints) # Check keypoints aug_fun 00: [[53 58]]\n",
    "#     data = {\"image\":image}\n",
    "    aug_data = transforms_AToe(image=image, keypoints=keypoints)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_xy  = aug_data[\"keypoints\"]\n",
    "#     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.cast(aug_img, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "    \n",
    "    aug_xy = tf.cast(aug_xy, tf.float32) #有些變形輸出是double\n",
    "#     print('Check aug_xy:', aug_xy) # Check aug_xy: [(95, 45)] #印到這邊都是對的\n",
    "    return aug_img, aug_xy \n",
    "\n",
    "# @tf.function\n",
    "def process_data_AToe(image, keypoints, img_size):\n",
    "    \n",
    "    print('Check keypoints process01:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "        \n",
    "#     keypoints = tf.make_ndarray(keypoints)\n",
    "#     keypoints = np.array(keypoints)\n",
    "#     keypoints = list(keypoints)\n",
    "#     keypoints = np.asarray(keypoints, dtype=np.float32)\n",
    "#     keypoints = tf.make_ndarray(keypoints.op.get_attr('value'))\n",
    "\n",
    "#     keypoints = tf.reshape(keypoints, [1, 2])\n",
    "    keypoints = tf.reshape(keypoints, [1, 2]) # for 'convert_keypoint_to_albumentations'\n",
    "#     keypoints = np.reshape(keypoints, (1, 2))#not support tensor with np.call.\n",
    "\n",
    "    print('Check keypoints process02:', keypoints, np.shape(keypoints), type(keypoints))\n",
    "\n",
    "#     aug_img, aug_xy = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "#     aug_img, aug_xy = tf.py_function(func=aug_fn, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.int64])#for tensors.\n",
    "    aug_img, aug_xy = tf.numpy_function(func=aug_fn_AToe, inp=[image, keypoints, img_size], Tout=[tf.float32, tf.float32])\n",
    "    print('Check keypoints process03:', aug_xy)\n",
    "    \n",
    "    aug_xy = tf.reshape(aug_xy, [2,]) # for 'tf ds tarining'\n",
    "    print('Check keypoints process04:', aug_xy)\n",
    "        \n",
    "    return aug_img, aug_xy \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_shapes(img, label, img_shape=(120,120,3)):\n",
    "    img.set_shape(img_shape)\n",
    "#     label.set_shape([]) # commited for go around error\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare train_ds_prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance_cache_train(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache.\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "        ds = ds.map(partial(process_data, img_size=120),num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "    ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def configure_for_performance_cache_train_AToe(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache.\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "        ds = ds.map(partial(process_data_AToe, img_size=120),num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "    ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def configure_for_performance_cache_train_oneof(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "#     \"\"\"#TODO: need to check the parse logic of ds.cache.\n",
    "#     if cache:\n",
    "#         print(\"Check cache-f1 to file:\", cache)\n",
    "#         if isinstance(cache, str):\n",
    "#             ds = ds.cache(cache)\n",
    "#             print(\"Check cache-f2 to file:\", cache)\n",
    "#     else:\n",
    "#         ds = ds.cache()\n",
    "#         print(\"Check cache in memory:\", cache)\n",
    "#     \"\"\"    \n",
    "#     if cache:\n",
    "#         ds = ds.cache()\n",
    "#         print(\"Check cache in memory:Y\", cache)\n",
    "#     else:\n",
    "#         print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "#     if augment:\n",
    "#         ds = ds.map(partial(process_data_oneof, img_size=120),num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "#         print(\"Check augment :Y\", augment)\n",
    "#     else:\n",
    "#         print(\"Check augment :N\", augment)\n",
    "    \n",
    "#     #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "#     #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "#     ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=True) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "#     ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "#     print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "#     return ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def configure_for_performance_cache_val(ds, cache=True, augment=False):\n",
    "\n",
    "    \n",
    "    \"\"\"#TODO: need to check the parse logic of ds.cache\n",
    "    TODO:test remove ds.shuffle from val_ds.\n",
    "    .\n",
    "    if cache:\n",
    "        print(\"Check cache-f1 to file:\", cache)\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"Check cache-f2 to file:\", cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:\", cache)\n",
    "    \"\"\"    \n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "    if augment:\n",
    "#         ds = ds.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(AA, num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(RA, num_parallel_calls=AUTOTUNE)\n",
    "        print(\"Check augment :Y\", augment)\n",
    "    else:\n",
    "        print(\"Check augment :N\", augment)\n",
    "    \n",
    "    #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "    #ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "#     ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=False) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(MULTI_BATCH_SIZE)#MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    print(\"Check ds cache[{}] and augment[{}]\".format(cache, augment))\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "# \"\"\"\n",
    "# # Toe ds_pre\n",
    "# train_ds_pre_toe = configure_for_performance_cache_train(train_ds_map_toe)\n",
    "\n",
    "# # Heel ds_pre\n",
    "# train_ds_pre_heel = configure_for_performance_cache_val(train_ds_map_heel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All split ds_prefetch\n",
    "* train_ds_map_toe_s = train_ds_map_toe.skip(val_size)\n",
    "* valid_ds_map_toe_s = train_ds_map_toe.take(val_size)\n",
    "\n",
    "* train_ds_map_heel_s = train_ds_map_heel.skip(val_size)\n",
    "* valid_ds_map_heel_s = train_ds_map_heel.take(val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "# \"\"\"\n",
    "# # Toe ds_pre\n",
    "# train_ds_pre_toe_s = configure_for_performance_cache_train(train_ds_map_toe_s, augment=True)\n",
    "# valid_ds_pre_toe_s = configure_for_performance_cache_val(valid_ds_map_toe_s)\n",
    "\n",
    "# # Heel ds_pre\n",
    "# train_ds_pre_heel_s = configure_for_performance_cache_train(train_ds_map_heel_s, augment=True)\n",
    "# valid_ds_pre_heel_s = configure_for_performance_cache_val(valid_ds_map_heel_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ds_prefetch samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create it_ds once\n",
    "# it_train_ds_pre_toe_s = iter(train_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # for albu keypoint\n",
    "\n",
    "# # for original return aug_img, , aug_xy \n",
    "\n",
    "\n",
    "# image_batch, label_batch = next(it_train_ds_pre_toe_s)\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "# for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "#     print(f'Check lables: {label_batch[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create it_ds once\n",
    "# it_train_ds_pre_heel_s = iter(train_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # for albu keypoint\n",
    "\n",
    "# # for original return aug_img, , aug_xy \n",
    "\n",
    "\n",
    "# image_batch, label_batch = next(it_train_ds_pre_heel_s)\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "# for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "#     print(f'Check lables: {label_batch[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create it_ds once\n",
    "# it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # for albu keypoint\n",
    "\n",
    "# # for return aug_img, aug_xy \n",
    "\n",
    "\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# # for images, labels in valid_ds_pre_toe_s.take(1):\n",
    "# print('batch * multi:', len(label_batch), ', MULTI_BATCH_SIZE=', MULTI_BATCH_SIZE)\n",
    "# for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=13, mew=2.5)\n",
    "\n",
    "#     print(f'Check lables: {label_batch[i]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Loss function\n",
    "\n",
    "* mae\n",
    "* euclidean distance\n",
    "* others\n",
    "\n",
    "\n",
    "        # 'x' is [[1, 1, 1]\n",
    "        #         [1, 1, 1]]\n",
    "        tf.reduce_sum(x) ==> 6\n",
    "        tf.reduce_sum(x, 0) ==> [2, 2, 2]\n",
    "        tf.reduce_sum(x, 1) ==> [3, 3]\n",
    "        the function is default for 2-D array, therefor, in our 1-D [x1,y1] to [x2,y2] the axis should be '0' or just leave it.\n",
    "        \n",
    "        tf.sqrt need \tA tf.Tensor of type bfloat16, half, float32, float64, complex64, complex128\n",
    "        so, convert it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be -> tf.Tensor([56 39], shape=(2,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [10, 10]\n",
    "y_pred = [10, 20]\n",
    "\n",
    "# y_true = [1.00000000000000000000123, 10]\n",
    "# y_pred = [1.0, 10.000000000000000000000000001]\n",
    "\n",
    "# y_true = [1.0000123, 10]\n",
    "# y_pred = [1.0, 10.0000321]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae\n",
    "\n",
    "loss_mae = tf.keras.losses.MAE(\n",
    "    y_true, y_pred\n",
    ")\n",
    "\n",
    "loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ed\n",
    "\n",
    "# loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.constant(y_true) - tf.constant(y_pred)), 0))\n",
    "\n",
    "# loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.Variable(y_true) - tf.Variable(y_pred)), 0))\n",
    "\n",
    "loss_ed = tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0))\n",
    "\n",
    "loss_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ed_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0))\n",
    "\n",
    "# fix NaN in euclidean distance\n",
    "# tf.maximum(d, 1e-9), to keep atlease is 1e-9.\n",
    "# def ed_loss(y_true, y_pred):\n",
    "#     return tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 0), 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the euclidean distance loss\n",
    "ed_loss(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean Euclidean distance \n",
    "\n",
    "* here the y_true and y_pred is 2-D array. the axis use 1.\n",
    "\n",
    "\n",
    "* NOTE: LB評分的mean euclidean distance功能，應該跟model.evaluate()一樣so不需重新寫。evaluate()會自動用loss (model.metrics_names)計算後在自動平均，而模型loss我們是用ed-loss取代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [[60, 76],\n",
    "#        [58, 49 ],\n",
    "#        [63, 67 ],\n",
    "#        [58 , 57]]\n",
    "# y_pred = [[59.927303, 76.471214],\n",
    "#        [58.056904, 49.98754 ],\n",
    "#        [63.067844, 67.03861 ],\n",
    "#        [58.70202 , 57.372707]]\n",
    "\n",
    "y_true = [[60, 70],\n",
    "       [70, 80]]\n",
    "y_pred = [[61, 71],\n",
    "       [72, 82]]\n",
    "\n",
    "# y_true = [(60, 70),\n",
    "#        (70, 80)]\n",
    "# y_pred = [(61, 71),\n",
    "#        (72, 82)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ed_metric_2d(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等於true, pred點位ed的平均，LB評分方式。(toe/heel即p1,p2要個別算ed一次再相加)\n",
    "def ed_metric_2d_mean(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(tf.cast(y_true, tf.float32) - tf.cast(y_pred, tf.float32)), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for re-scale back xy \n",
    "# return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "# return img, [(x2-60)/60,((y2-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "\n",
    "# 等於true, pred點位ed的平均，LB評分方式。(toe/heel即p1,p2要個別算ed一次再相加)\n",
    "def edRescal(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(tf.cast((y_true*60)+60, tf.float32) - tf.cast((y_pred*60)+60, tf.float32)), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d_mean(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_metric_2d_mean(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFNE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe mae better than ed loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dump lr\n",
    "\"\"\"\n",
    "ep_num_transf = 500\n",
    "\n",
    "\n",
    "\n",
    "def lrdump(epoch):\n",
    "    \n",
    "    #step_size = 100\n",
    "    lr_max = 0.006\n",
    "    lr_min = 0.001\n",
    "    lr_start = 0.01\n",
    "\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 100\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "\n",
    "    \n",
    "    # warm up\n",
    "    if epoch < lr_init_ep:\n",
    "        lr = (lr_max - lr_min) / lr_ramp_ep * epoch + lr_min    \n",
    "        \n",
    "    elif lr_init_ep -1 < epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(ep_num_transf)]\n",
    "y = [lrdump(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e, lr in zip(rng,y):\n",
    "    print('{}\\t {}\\n'.format(e, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clr3\n",
    "# warm up 10% of epoch: it can reduce fall in local min in inital steps.\n",
    "\n",
    "\n",
    "ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "def clr3(epoch):\n",
    "    \n",
    "    \n",
    "    step_size = 25 # currently best for foot pp\n",
    "    max_lr = 0.01 # currently best for foot pp\n",
    "    base_lr = 1e-6 # 1e-6 1e-7\n",
    "\n",
    "    # warm up\n",
    "    lr_init_ep = 0\n",
    "    lr_ramp_ep = 100\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.5\n",
    "\n",
    "    iterations = epoch\n",
    "    cycle = np.floor(1+iterations/(2*step_size))\n",
    "    x = np.abs(iterations/step_size - 2*cycle + 1)\n",
    "    lr = base_lr + (max_lr-base_lr)*np.maximum(0, (1-x))\n",
    "    \n",
    "    #todo: boost the lr at initial setps.\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else max_lr\n",
    "#     initial_lr = lambda epoch: lr if epoch > step_size else boost_lr\n",
    "#     lr = initial_lr(epoch)\n",
    "    #todo: boost the lr at fist step_size.\n",
    "    \n",
    "    # warm up\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = (max_lr - base_lr) / lr_ramp_ep * epoch + base_lr\n",
    "    \n",
    "    decay = ((epoch+1)/ep_num)\n",
    "    base_part = 1.001 #1.1\n",
    "#     print(decay)\n",
    "    return lr * (base_part-decay) * lr_decay # supressed the lr!\n",
    "\n",
    "\n",
    "rng = [i for i in range(ep_num)]\n",
    "y = [clr3(x) for x in rng]\n",
    "sns.set(style='darkgrid')\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4999999999999966e-08 ~ 0.004459954505 1e-2~1e-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# \"\"\"\n",
    "# cosine_decay_restarts是cosine_decay的cycle版本。\n",
    "# first_decay_steps是指第一次完全下降的step數，\n",
    "# t_mul是指每一次循環的步數都將乘以t_mul倍，\n",
    "# m_mul指每一次循環重新開始時的初始lr是上一次循環初始值的m_mul倍。\n",
    "# alpha\n",
    "# \"\"\"\n",
    "\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "\n",
    "# ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "# def CosineDecayCLRWarmUp(epoch):\n",
    "    \n",
    "#     #step_size = 25 # currently best for foot pp\n",
    "#     max_lr = 1e-2 # currently best for foot pp\n",
    "#     base_lr = 1e-8# 1e-6 1e-7\n",
    "\n",
    "#     # warm up\n",
    "#     lr_init_ep = 0\n",
    "#     lr_ramp_ep = 100\n",
    "#     lr_sus_ep  = 0\n",
    "#     lr_decay   = 0.8\n",
    "\n",
    "\n",
    "#     initial_learning_rate = 1e-2\n",
    "#     first_decay_steps = 100\n",
    "\n",
    "\n",
    "#     lr_decayed_fn = (\n",
    "#       tf.keras.experimental.CosineDecayRestarts(\n",
    "#           initial_learning_rate,\n",
    "#           first_decay_steps,\n",
    "#           t_mul=1.0,\n",
    "#           m_mul=0.8,\n",
    "#           alpha = 0.000001,\n",
    "#           name=\"CCosineDecayRestarts\"))\n",
    "    \n",
    "#     # warm up\n",
    "#     if epoch < lr_ramp_ep:\n",
    "#         lr = (max_lr - base_lr) / lr_ramp_ep * epoch + base_lr    \n",
    "#     else:\n",
    "#         lr = lr_decayed_fn(epoch)\n",
    "#     return lr\n",
    "\n",
    "\n",
    "\n",
    "# rng = [i for i in range(ep_num)]\n",
    "# y = [CosineDecayCLRWarmUp(x) for x in rng]\n",
    "# sns.set(style='darkgrid')\n",
    "# fig, ax = plt.subplots(figsize=(20, 6))\n",
    "# # plt.ylim(.0000000000000001, .01)# for too large loss\n",
    "# ax.yaxis.set_major_formatter(FormatStrFormatter('%.12f'))# for too small loss\n",
    "# plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# \"\"\"\n",
    "# cosine_decay_restarts是cosine_decay的cycle版本。\n",
    "# first_decay_steps是指第一次完全下降的step數，\n",
    "# t_mul是指每一次循環的步數都將乘以t_mul倍，\n",
    "# m_mul指每一次循環重新開始時的初始lr是上一次循環初始值的m_mul倍。\n",
    "# alpha\n",
    "# \"\"\"\n",
    "\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "\n",
    "# ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "# def CosineDecayCLRWarmUpLSW(epoch):\n",
    "    \n",
    "#     #step_size = 25 # currently best for foot pp\n",
    "#     max_lr = 1e-3 # currently best for foot pp\n",
    "#     base_lr = 1e-6# 1e-6 1e-7\n",
    "\n",
    "#     # warm up\n",
    "#     lr_init_ep = 0\n",
    "#     lr_ramp_ep = 20\n",
    "#     lr_sus_ep  = 0\n",
    "#     lr_decay   = 0.8\n",
    "\n",
    "\n",
    "#     initial_learning_rate = 1e-3\n",
    "#     first_decay_steps = 50\n",
    "\n",
    "\n",
    "#     lr_decayed_fn = (\n",
    "#       tf.keras.experimental.CosineDecayRestarts(\n",
    "#           initial_learning_rate,\n",
    "#           first_decay_steps,\n",
    "#           t_mul=1.0,\n",
    "#           m_mul=0.8,\n",
    "#           alpha = 0.000001,\n",
    "#           name=\"CCosineDecayRestarts\"))\n",
    "    \n",
    "#     # warm up\n",
    "#     if epoch < lr_ramp_ep:\n",
    "#         lr = (max_lr - base_lr) / lr_ramp_ep * epoch + base_lr    \n",
    "#     else:\n",
    "#         lr = lr_decayed_fn(epoch-lr_ramp_ep)\n",
    "#     return lr\n",
    "\n",
    "\n",
    "\n",
    "# rng = [i for i in range(ep_num)]\n",
    "# y = [CosineDecayCLRWarmUpLSW(x) for x in rng]\n",
    "# sns.set(style='darkgrid')\n",
    "# fig, ax = plt.subplots(figsize=(20, 6))\n",
    "# # plt.ylim(.0000000000000001, .01)# for too large loss\n",
    "# ax.yaxis.set_major_formatter(FormatStrFormatter('%.12f'))# for too small loss\n",
    "# plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# \"\"\"\n",
    "# cosine_decay_restarts是cosine_decay的cycle版本。\n",
    "# first_decay_steps是指第一次完全下降的step數，\n",
    "# t_mul是指每一次循環的步數都將乘以t_mul倍，\n",
    "# m_mul指每一次循環重新開始時的初始lr是上一次循環初始值的m_mul倍。\n",
    "# alpha\n",
    "# \"\"\"\n",
    "\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "\n",
    "# ep_num = 1000\n",
    "\n",
    "\n",
    "\n",
    "# def CosineDecayCLRWarmUpLSW_2(epoch):\n",
    "    \n",
    "#     #step_size = 25 # currently best for foot pp\n",
    "#     max_lr = 1e-2 # currently best for foot pp\n",
    "#     base_lr = 1e-6# 1e-6 1e-7\n",
    "\n",
    "#     # warm up\n",
    "#     lr_init_ep = 0\n",
    "#     lr_ramp_ep = 20\n",
    "#     lr_sus_ep  = 0\n",
    "#     #lr_decay   = 0.8\n",
    "\n",
    "\n",
    "#     initial_learning_rate = 1e-2\n",
    "#     first_decay_steps = 50\n",
    "\n",
    "\n",
    "#     lr_decayed_fn = (\n",
    "#       tf.keras.experimental.CosineDecayRestarts(\n",
    "#           initial_learning_rate,\n",
    "#           first_decay_steps,\n",
    "#           t_mul=1,\n",
    "#           m_mul=1,\n",
    "#           alpha = 0.000001,\n",
    "#           name=\"CCosineDecayRestarts\"))\n",
    "    \n",
    "#     # warm up\n",
    "#     if epoch < lr_ramp_ep:\n",
    "#         lr = (max_lr - base_lr) / lr_ramp_ep * epoch + base_lr    \n",
    "#     else:\n",
    "#         lr = lr_decayed_fn(epoch-lr_ramp_ep)\n",
    "#     return lr\n",
    "\n",
    "\n",
    "\n",
    "# rng = [i for i in range(ep_num)]\n",
    "# y = [CosineDecayCLRWarmUpLSW_2(x) for x in rng]\n",
    "# sns.set(style='darkgrid')\n",
    "# fig, ax = plt.subplots(figsize=(20, 6))\n",
    "# # plt.ylim(.0000000000000001, .01)# for too large loss\n",
    "# ax.yaxis.set_major_formatter(FormatStrFormatter('%.12f'))# for too small loss\n",
    "# plt.plot(rng, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} ~ {}'.format(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8774175103430935e-08 ~ 0.0010000000474974513 1e-3 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_reduceonplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLRtoe(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "#             datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "#             epoch + 1,\n",
    "#             self.model.optimizer.lr.numpy()))\n",
    "        print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "        epoch + 1,\n",
    "        model_toe.optimizer._decayed_lr(tf.float32).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLRheel(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "#                                               model_heel.optimizer.lr.numpy()))\n",
    "        print('\\n[{}] Learning rate for epoch {} is {}'.format(\n",
    "        datetime.now().strftime(\"%Y%m%d-%H%M-%S\"), \n",
    "        epoch + 1,\n",
    "        model_heel.optimizer._decayed_lr(tf.float32).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output dir and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_log_dir(log_dir_name):\n",
    "    try:\n",
    "        os.makedirs(log_dir_name)\n",
    "    except OSError as e:\n",
    "        print(\"This log dir exist.\")\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise ValueError(\"we got problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = 'val_loss' #'val_loss' 'val_accuracy' if use ed_loss it still the loss here.\n",
    "\n",
    "log_dir_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "\n",
    "# mk_log_dir(datetime.now().strftime(\"%Y%m%d-%H%M%S\") )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use once at the time\n",
    "mk_log_dir(log_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'EfficientNetB0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_best_model_name\n",
    "\n",
    "# best_model_name = './' + model_name + '_bs-' + str(BATCH_SIZE) + '_s-' + str(img_height) + '_' + \"ep-{epoch:02d}-vloss-{val_loss:.2f}\" +'_best-weight.h5'\n",
    "# best_model_name = '{model_name}-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "#best_model_name = './' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + monitor + '_best.h5'\n",
    "# best_model_name = './Leaf_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_best_' + monitor + '.h5'\n",
    "\n",
    "# best_model_name = './cop' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_best_' + monitor + '.h5'\n",
    "\n",
    "def get_best_model_name(th, K):\n",
    "    return './' + log_dir_name + '/' + th + '_K' + K + '_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_best_' + monitor + '.h5'\n",
    "\n",
    "# th = 'toe'\n",
    "# # th = 'heel'\n",
    "\n",
    "# # print(get_best_model_name(th,K))\n",
    "\n",
    "# best_model_name = get_best_model_name(th, K)\n",
    "\n",
    "\n",
    "# best_model_save = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_name, \n",
    "#                              save_best_only = True, \n",
    "#                              save_weights_only = False,\n",
    "#                              monitor = monitor, \n",
    "#                              mode = 'auto', verbose = 1)\n",
    "# print('best_model_name:', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir_name + \"/logs/toe/\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "# #     tensorboard_callback,\n",
    "#     best_model_save,\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=20), #patience=step_size or ep_num\n",
    "# #     lr_reduceonplateau,\n",
    "#     tf.keras.callbacks.LearningRateScheduler(lrdump),#lrdump, decay or lrfn or lrfn2. clr\n",
    "#     PrintLRtoe()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"efnB0LSW\"\n",
    "\n",
    "# Transfer learning from pre-trained weights\n",
    "def build_efn_model(outputnum, top_dropout_rate, drop_connect_rate):\n",
    "#     base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(120,120,3),drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=(120,120,3),drop_connect_rate=drop_connect_rate) #{'imagenet', None}\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    base_model.trainable = False\n",
    "    print(\"base_model.trainable : \", base_model.trainable)\n",
    "\n",
    "    # Rebuild top\n",
    "    gap2d = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    BNL = tf.keras.layers.BatchNormalization()(gap2d) #tood: remove#\n",
    "    dropout = tf.keras.layers.Dropout(top_dropout_rate)(BNL)#tood: remove# J add dropout, for flood 0.2 is ok. for leaf 0.4 is better.\n",
    "    outputs = tf.keras.layers.Dense(outputnum)(dropout)# remove activation for regression output (to default, the linear), , activation = 'relu' no help\n",
    "\n",
    "    # Compile new model\n",
    "    model = tf.keras.Model(base_model.input, outputs, name=model_name)\n",
    "\n",
    "\n",
    "#     # unfreeze the top #fine_tune_at# layers while leaving BatchNorm layers frozen\n",
    "#     fine_tune_at = 20 #10 #241 #20\n",
    "#     print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "#     for layer in model_toe.layers[-fine_tune_at:]:\n",
    "#         if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "#             layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Supervised pre-training 減少每次fold都要重新train的時間\n",
    "只先改toe\"\"\"\n",
    "\n",
    "# Transfer learning from pre-trained weights\n",
    "def load_pretrained_efn_model():\n",
    "    pre_model_toe_name = \"20210224-200728/toe_K0_EfficientNetB0_bs64_w120_best_val_loss.h5\"\n",
    "    model = tf.keras.models.load_model(pre_model_toe_name,compile=False)\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "#     print(\"base_model.trainable : \", base_model.trainable)\n",
    "\n",
    "#     # Rebuild top\n",
    "#     gap2d = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "#     BNL = tf.keras.layers.BatchNormalization()(gap2d) #tood: remove#\n",
    "#     dropout = tf.keras.layers.Dropout(top_dropout_rate)(BNL)#tood: remove# J add dropout, for flood 0.2 is ok. for leaf 0.4 is better.\n",
    "#     outputs = tf.keras.layers.Dense(outputnum)(dropout)# remove activation for regression output (to default, the linear), , activation = 'relu' no help\n",
    "\n",
    "#     # Compile new model\n",
    "#     model = tf.keras.Model(base_model.input, outputs, name=model_name)\n",
    "\n",
    "\n",
    "#     # unfreeze the top #fine_tune_at# layers while leaving BatchNorm layers frozen\n",
    "    fine_tune_at = 4 #10 #241 #20\n",
    "    print('[Note] Now create model fine tuneing at Top-{} layers!'.format(fine_tune_at))\n",
    "    for layer in model.layers[-fine_tune_at:]:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            print('layer trainable +1', layer.name)\n",
    "            layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model):\n",
    "#\n",
    "#'block7a_expand_conv'20 'block6c_expand_conv'50 'block6a_expand_conv'79 'block5b_expand_conv'109 'block4a_expand_conv' 166 \n",
    "#\n",
    "    model.trainable = True\n",
    "#     set_trainable = False\n",
    "#     for layer in model.layers:\n",
    "#         if layer.name == 'block5b_expand_conv': \n",
    "#             set_trainable = True\n",
    "#         if set_trainable:\n",
    "#             layer.trainable = True\n",
    "#         else:\n",
    "#             layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top_dropout_rate = 0.8 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "# drop_connect_rate = 0.9 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "# outputnum = 2\n",
    "# with strategy.scope():\n",
    "#     model_toe = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model_toe.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = 0\n",
    "# nt = 0\n",
    "# for layer in model_toe.layers:\n",
    "#     if layer.trainable:\n",
    "#         tt +=1\n",
    "#         print(f'{layer.name}')\n",
    "#     else:\n",
    "#         nt +=1\n",
    "# print(f'tt: {tt}, nt:{nt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_trainOrNot_layers(model, printlayers=False):\n",
    "    tt = 0\n",
    "    nt = 0\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            tt +=1\n",
    "            if printlayers:\n",
    "                print(f'{layer.name}')\n",
    "        else:\n",
    "            nt +=1\n",
    "    print('\\n*********************************** Start fine tune ***********************************')\n",
    "    print(f'tt: {tt}, nt:{nt}, total layers:{tt+nt}')\n",
    "    print('*********************************** Start fine tune ***********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_model_trainOrNot_layers(model_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # fit the model on all data\n",
    "# history_toe = model_toe.fit(train_ds_pre_toe_s, \n",
    "#                       verbose=1, \n",
    "#                       epochs=ep_num_transf, \n",
    "#                       validation_data=valid_ds_pre_toe_s, \n",
    "#                       callbacks=callbacks)#, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Training\n",
    "\n",
    "2021-02-23 v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toe K-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# big K = 5 (fold 0 ~ 4) \n",
    "KFlodNum = 1\n",
    "\n",
    "\n",
    "\n",
    "history_toe = []\n",
    "history_toe_finetune = []\n",
    "\n",
    "#above until 'train_ds_map_toe now' to 'train_ds_map_toe_s', 'valid_ds_map_toe_s'\n",
    "for k in range(KFlodNum):\n",
    "    \n",
    "    \n",
    "    # Split data to train/valid with K-Fold #\n",
    "    print(\"\\n \\n K = \", k, \"\\n\")\n",
    "    # Toe split\n",
    "    train_ds_map_toe_s, valid_ds_map_toe_s = get_KFold_ds(train_ds_map_toe, K=k)\n",
    "    \n",
    "    # Toe ds_pre\n",
    "    train_ds_pre_toe_s = configure_for_performance_cache_train(train_ds_map_toe_s, augment=True)\n",
    "    valid_ds_pre_toe_s = configure_for_performance_cache_val(valid_ds_map_toe_s)\n",
    "    \n",
    "    \n",
    "#     # heel split\n",
    "#     train_ds_map_heel_s, valid_ds_map_heel_s = get_KFold_ds(train_ds_map_heel, K=k)\n",
    "#     # Heel ds_pre\n",
    "#     train_ds_pre_heel_s = configure_for_performance_cache_train(train_ds_map_heel_s, augment=True)\n",
    "#     valid_ds_pre_heel_s = configure_for_performance_cache_val(valid_ds_map_heel_s)\n",
    "    \n",
    "    \n",
    "    # Train K-Model with transfer learnling #\n",
    "    \n",
    "    # Toe model, TL\n",
    "    th = 'toe'\n",
    "    # th = 'heel'\n",
    "    best_model_name = get_best_model_name(th, K=str(k))\n",
    "    best_model_save = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_name, \n",
    "                                 save_best_only = True, \n",
    "                                 save_weights_only = False,\n",
    "                                 monitor = monitor, \n",
    "                                 mode = 'auto', verbose = 1)\n",
    "    callbacks_toe_tl = [\n",
    "                    #     tensorboard_callback,\n",
    "                        best_model_save,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=20), #patience=step_size or ep_num\n",
    "                    #     lr_reduceonplateau,\n",
    "                        tf.keras.callbacks.LearningRateScheduler(lrdump),#lrdump, decay or lrfn or lrfn2. clr\n",
    "                        PrintLRtoe()\n",
    "                        ]\n",
    "    callbacks_toe_fn = [\n",
    "                    #     tensorboard_callback,\n",
    "                        best_model_save,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=100), #patience=step_size or ep_num\n",
    "                    #     lr_reduceonplateau,\n",
    "                        tf.keras.callbacks.LearningRateScheduler(clr3),#lrdump, decay or lrfn or lrfn2. clr, CosineDecayCLRWarmUp, CosineDecayCLRWarmUpLSW\n",
    "                        PrintLRtoe()\n",
    "                    ]\n",
    "    print('best_model_name:', best_model_name)\n",
    "\n",
    "\n",
    "    top_dropout_rate = 0.8 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "    drop_connect_rate = 0.9 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "    outputnum = 2\n",
    "    with strategy.scope():\n",
    "        #model_toe = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)\n",
    "        model_toe = make_model()\n",
    "        model_toe.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),#RMSprop , Adam, SGD Adadelta(learning_rate=0.001), if set lr_callback the learning_rate=0.001 will not effeced.\n",
    "                    loss=ed_metric_2d_mean)\n",
    "        \n",
    "#         model_toe = load_pretrained_efn_model() # from 20210224-200728 ed5.3\n",
    "#         count_model_trainOrNot_layers(model_toe)\n",
    "        \n",
    "#     # fit the model on all data\n",
    "    hist = model_toe.fit(train_ds_pre_toe_s, \n",
    "                          verbose=1, \n",
    "                          epochs=ep_num_transf, \n",
    "                          validation_data=valid_ds_pre_toe_s, \n",
    "                          callbacks=callbacks_toe_tl)#, validation_split=0.1)\n",
    "    history_toe.append(hist)\n",
    "    \n",
    "      \n",
    "    # Train K-Model with fine tune #\n",
    "    \n",
    "    # Toe model, FT\n",
    "    unfreeze_model(model_toe)\n",
    "    count_model_trainOrNot_layers(model_toe)\n",
    "    # fit the model on all data\n",
    "    hist = model_toe.fit(train_ds_pre_toe_s, \n",
    "                          verbose=1, \n",
    "                          epochs=ep_num, \n",
    "                          validation_data=valid_ds_pre_toe_s, \n",
    "                          callbacks=callbacks_toe_fn)#, validation_split=0.1)\n",
    "    history_toe_finetune.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ED sum\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "t_vl = []\n",
    "# h_vl = []\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "    t_v, _ = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "#     h_v, _ = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    \n",
    "    t_vl.append(t_v)\n",
    "#     h_vl.append(h_v)\n",
    "\n",
    "# t_vl = np.mean(t_vl, axis=0)\n",
    "# h_vl = np.mean(h_vl, axis=0)\n",
    "# print(f'{round(t_vl,5)} + {round(h_vl,5)} = {round(t_vl + h_vl,5)}')\n",
    "\n",
    "t_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{log_dir_name}/toe_FNED.txt', t_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum plot losses toe-tl\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_toe[k].history['loss'])\n",
    "    plt.plot(history_toe[k].history['val_loss'])\n",
    "\n",
    "    \n",
    "plt.title('K-model ed loss toe-TL')\n",
    "plt.ylabel('ed loss'), plt.ylim(5, 80)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_toe_Ksum_TL.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Single plot loss toe-tl\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(history_toe[k].history['loss'])\n",
    "    plt.plot(history_toe[k].history['val_loss'])\n",
    "    plt.title('K-model ed loss toe-TL')\n",
    "    plt.ylabel('ed loss'), plt.ylim(5, 20)# for too large loss\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "    # plt.show()\n",
    "\n",
    "    # save plot : comment plo.show in jupyter notebook.\n",
    "    def get_valloss(his_v_l):   \n",
    "        return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "    vl, ep = get_valloss(history_toe[k].history['val_loss'])\n",
    "    plt.savefig(f'{log_dir_name}/{log_dir_name}_toe_K{k}_TL_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "t_vl = []\n",
    "# h_vl = []\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "    t_v, _ = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "#     h_v, _ = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    \n",
    "    t_vl.append(t_v)\n",
    "    \n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('[ toe_finetune ] \\n ED loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color)\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_toe_finetune[k].history['loss'])\n",
    "    plt.plot(history_toe_finetune[k].history['val_loss'])\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "ax1.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper left') \n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_toe_finetune[0].history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(['lr'], loc='upper right') \n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # save plot : comment plo.show in jupyter notebook.\n",
    "# def get_valloss(his_v_l):   \n",
    "#     return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "# vl, ep = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "\n",
    "\n",
    "t_vl = np.mean(t_vl, axis=0)\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_toe_ft_Ksum-clr_ed{round(t_vl,4)}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum plot losses toe-ft\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_toe_finetune[k].history['loss'])\n",
    "    plt.plot(history_toe_finetune[k].history['val_loss'])\n",
    "\n",
    "    \n",
    "plt.title('K-model ed loss toe-FT')\n",
    "plt.ylabel('ed loss'), plt.ylim(4, 20)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_toe_Ksum_FT.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Single plot loss toe-FT\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(history_toe_finetune[k].history['loss'])\n",
    "    plt.plot(history_toe_finetune[k].history['val_loss'])\n",
    "    plt.title('K-model ed loss toe-FT')\n",
    "    plt.ylabel('ed loss'), plt.ylim(4, 20)# for too large loss\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "    # plt.show()\n",
    "\n",
    "    # save plot : comment plo.show in jupyter notebook.\n",
    "    def get_valloss(his_v_l):   \n",
    "        return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "    vl, ep = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "    plt.savefig(f'{log_dir_name}/{log_dir_name}_toe_K{k}_FT_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heel K-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# big K = 5 (fold 0 ~ 4) \n",
    "# KFlodNum = 5 # follow Toe's K.\n",
    "\n",
    "\n",
    "\n",
    "history_heel = []\n",
    "history_heel_finetune = []\n",
    "\n",
    "#above until 'train_ds_map_toe now' to 'train_ds_map_toe_s', 'valid_ds_map_toe_s'\n",
    "for k in range(KFlodNum):\n",
    "    \n",
    "    \n",
    "    # Split data to train/valid with K-Fold #\n",
    "    print(\"K=\", k)\n",
    "#     # Toe split\n",
    "#     train_ds_map_toe_s, valid_ds_map_toe_s = get_KFold_ds(train_ds_map_toe, K=k)\n",
    "    \n",
    "#     # Toe ds_pre\n",
    "#     train_ds_pre_toe_s = configure_for_performance_cache_train(train_ds_map_toe_s, augment=True)\n",
    "#     valid_ds_pre_toe_s = configure_for_performance_cache_val(valid_ds_map_toe_s)\n",
    "    \n",
    "    \n",
    "    # heel split\n",
    "    train_ds_map_heel_s, valid_ds_map_heel_s = get_KFold_ds(train_ds_map_heel, K=k)\n",
    "    # Heel ds_pre\n",
    "    train_ds_pre_heel_s = configure_for_performance_cache_train_AToe(train_ds_map_heel_s, augment=True)\n",
    "    valid_ds_pre_heel_s = configure_for_performance_cache_val(valid_ds_map_heel_s)\n",
    "    \n",
    "    \n",
    "    # Train K-Model with transfer learnling #\n",
    "    \n",
    "    # Toe model, TL\n",
    "    #th = 'toe'\n",
    "    th = 'heel'\n",
    "    best_model_name = get_best_model_name(th, K=str(k))\n",
    "    best_model_save = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_name, \n",
    "                                 save_best_only = True, \n",
    "                                 save_weights_only = False,\n",
    "                                 monitor = monitor, \n",
    "                                 mode = 'auto', verbose = 1)\n",
    "    callbacks_heel_tl = [\n",
    "                    #     tensorboard_callback,\n",
    "                        best_model_save,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=20), #patience=step_size or ep_num\n",
    "                    #     lr_reduceonplateau,\n",
    "                        tf.keras.callbacks.LearningRateScheduler(lrdump),#lrdump, decay or lrfn or lrfn2. clr\n",
    "                        PrintLRtoe()\n",
    "                        ]\n",
    "    callbacks_heel_fn = [\n",
    "                    #     tensorboard_callback,\n",
    "                        best_model_save,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=100), #patience=step_size or ep_num\n",
    "                    #     lr_reduceonplateau,\n",
    "                        tf.keras.callbacks.LearningRateScheduler(clr3),#lrdump, decay or lrfn or lrfn2. clr, CosineDecayCLRWarmUp, CosineDecayCLRWarmUpLSW\n",
    "                        PrintLRheel()\n",
    "                    ]\n",
    "    print('best_model_name:', best_model_name)\n",
    "\n",
    "\n",
    "    top_dropout_rate = 0.4 #less dp rate, say 0.1, train_loss will lower than val_loss\n",
    "    drop_connect_rate = 0.4 #for efnet This parameter serves as a toggle for extra regularization in finetuning, but does not affect loaded weights.\n",
    "    outputnum = 2\n",
    "    with strategy.scope():\n",
    "        model_heel = build_efn_model(outputnum, top_dropout_rate, drop_connect_rate)\n",
    "    # fit the model on all data\n",
    "    hist = model_heel.fit(train_ds_pre_heel_s, \n",
    "                          verbose=1, \n",
    "                          epochs=ep_num_transf, \n",
    "                          validation_data=valid_ds_pre_heel_s, \n",
    "                          callbacks=callbacks_heel_tl)#, validation_split=0.1)\n",
    "    history_heel.append(hist)\n",
    "    \n",
    "      \n",
    "    # Train K-Model with fine tune #\n",
    "    \n",
    "    # Toe model, FT\n",
    "    unfreeze_model(model_heel)\n",
    "    count_model_trainOrNot_layers(model_heel)\n",
    "    # fit the model on all data\n",
    "    hist = model_heel.fit(train_ds_pre_heel_s, \n",
    "                          verbose=1, \n",
    "                          epochs=ep_num, \n",
    "                          validation_data=valid_ds_pre_heel_s, \n",
    "                          callbacks=callbacks_heel_fn)#, validation_split=0.1)\n",
    "    history_heel_finetune.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ED sum\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "# t_vl = []\n",
    "h_vl = []\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "#     t_v, _ = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "    h_v, _ = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    \n",
    "#     t_vl.append(t_v)\n",
    "    h_vl.append(h_v)\n",
    "\n",
    "# t_vl = np.mean(t_vl, axis=0)\n",
    "# h_vl = np.mean(h_vl, axis=0)\n",
    "# print(f'{round(t_vl,5)} + {round(h_vl,5)} = {round(t_vl + h_vl,5)}')\n",
    "\n",
    "# t_vl\n",
    "h_vl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{log_dir_name}/heel_FNED.txt', h_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum plot losses heel-tl\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_heel[k].history['loss'])\n",
    "    plt.plot(history_heel[k].history['val_loss'])\n",
    "\n",
    "    \n",
    "plt.title('K-model ed loss heel-TL')\n",
    "plt.ylabel('ed loss'), plt.ylim(5, 50)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_heel_Ksum_TL.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Single plot loss heel-tl\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(history_heel[k].history['loss'])\n",
    "    plt.plot(history_heel[k].history['val_loss'])\n",
    "    plt.title('K-model ed loss heel-TL')\n",
    "    plt.ylabel('ed loss'), plt.ylim(5, 80)# for too large loss\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "    # plt.show()\n",
    "\n",
    "    # save plot : comment plo.show in jupyter notebook.\n",
    "    def get_valloss(his_v_l):   \n",
    "        return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "    vl, ep = get_valloss(history_heel[k].history['val_loss'])\n",
    "    plt.savefig(f'{log_dir_name}/{log_dir_name}_heel_K{k}_TL_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the loos the model trained.\n",
    "\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "# t_vl = []\n",
    "h_vl = []\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "#     t_v, _ = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "    h_v, _ = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    \n",
    "    h_vl.append(h_v)\n",
    "    \n",
    "# for different scales (different Y-axes)\n",
    "# fig, ax1 = plt.subplots()\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# nice to have this colorful tip.\n",
    "color = 'tab:red'\n",
    "\n",
    "ax1.set_title('[ heel_finetune ] \\n ED loss')\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('ed loss', color=color)\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_heel_finetune[k].history['loss'])\n",
    "    plt.plot(history_heel_finetune[k].history['val_loss'])\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.legend(['loss', 'val_loss'], loc='upper center') # legend may ocvered by next ax ploting. moved to end.\n",
    "ax1.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper right') \n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('learning rate', color=color)\n",
    "ax2.plot(history_heel_finetune[0].history['lr'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(['lr'], loc='upper right') \n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # save plot : comment plo.show in jupyter notebook.\n",
    "# def get_valloss(his_v_l):   \n",
    "#     return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "# vl, ep = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "\n",
    "\n",
    "# t_vl = np.mean(t_vl, axis=0)\n",
    "h_vl = np.mean(h_vl, axis=0)\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_heel_ft_Ksum-clr_ed{round(h_vl,4)}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum plot losses heel-ft\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "\n",
    "    plt.plot(history_heel_finetune[k].history['loss'])\n",
    "    plt.plot(history_heel_finetune[k].history['val_loss'])\n",
    "\n",
    "    \n",
    "plt.title('K-model ed loss heel-FT')\n",
    "plt.ylabel('ed loss'), plt.ylim(2, 20)# for too large loss\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['k0 loss', 'k0 val_loss', 'k1 loss', 'k1 val_loss', 'k2 loss', 'k2 val_loss', \n",
    "            'k3 loss', 'k3 val_loss', 'k4 loss', 'k4 val_loss'], loc='upper left') \n",
    "# plt.show()\n",
    "\n",
    "# save plot : comment plo.show in jupyter notebook.\n",
    "plt.savefig(f'{log_dir_name}/{log_dir_name}_heel_Ksum_FT.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Single plot loss heel-FT\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(history_heel_finetune[k].history['loss'])\n",
    "    plt.plot(history_heel_finetune[k].history['val_loss'])\n",
    "    plt.title('K-model ed loss heel-FT')\n",
    "    plt.ylabel('ed loss'), plt.ylim(2, 20)# for too large loss\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper left') \n",
    "    # plt.show()\n",
    "\n",
    "    # save plot : comment plo.show in jupyter notebook.\n",
    "    def get_valloss(his_v_l):   \n",
    "        return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "    vl, ep = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    plt.savefig(f'{log_dir_name}/{log_dir_name}_heel_K{k}_FT_clr_ed{round(vl,4)}@{ep}.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_toe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show after modl.fit\n",
    "# model_toe.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check metrics the model have.\n",
    "# history_toe.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model_toe, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model_toe, to_file='model_toe_conv_layer_blocks_LC2DLSW.png', show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "# Image(filename='model_toe_conv_layer_blocks_LC2DLSW.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show pp pred\n",
    "\n",
    "* we can switch toe/hell by comment it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFN Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)\n",
    "# # it_valid_ds_pre_heel_s = iter(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # image_batch, label_batch = next(valid_ds_pre_toe_s)\n",
    "\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "# # image_batch, label_batch = next(it_valid_ds_pre_heel_s)\n",
    "\n",
    "\n",
    "# pred = model_toe.predict_on_batch(image_batch) #predictions\n",
    "# # pred = model.predict_on_batch(image_batch) #Simple 2D CNN model predictions\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# for i in range(64):\n",
    "#     ax = plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(image_batch[i])\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     # note: y_offset_toe for ds image\n",
    "    \n",
    "#     #ground truth\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=15, mew=2)\n",
    "\n",
    "#     #pred\n",
    "#     plt.plot(pred[i][0], pred[i][1], 'k+', markersize=15, mew=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_ds一次做完即可不用分batch\n",
    "# neg = label_batch - pred\n",
    "# neg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(neg)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_abs = np.abs(neg)\n",
    "# neg_abs.mean(axis=0)#所有x 所有y個別平均  neg.mean(axis=0)#所有x 所有y個別平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ED 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred = neg_abs.mean(axis=0)\n",
    "# ed_metric_2d([0,0], [neg_abs.mean(axis=0)]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFN Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it_valid_ds_pre_toe_s = iter(valid_ds_pre_toe_s)\n",
    "# it_valid_ds_pre_heel_s = iter(valid_ds_pre_heel_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # image_batch, label_batch = next(valid_ds_pre_toe_s)\n",
    "\n",
    "# # image_batch, label_batch = next(it_valid_ds_pre_toe_s)\n",
    "# image_batch, label_batch = next(it_valid_ds_pre_heel_s)\n",
    "\n",
    "\n",
    "# pred = model_heel.predict_on_batch(image_batch) #predictions\n",
    "# # pred = model.predict_on_batch(image_batch) #Simple 2D CNN model predictions\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# for i in range(64):\n",
    "#     ax = plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(image_batch[i])\n",
    "#     plt.title(label_batch[i].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     # note: y_offset_toe for ds image\n",
    "    \n",
    "#     #ground truth\n",
    "#     plt.plot(label_batch[i].numpy()[0], label_batch[i].numpy()[1], 'r+', markersize=15, mew=2)\n",
    "\n",
    "#     #pred\n",
    "#     plt.plot(pred[i][0], pred[i][1], 'k+', markersize=15, mew=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_ds一次做完即可不用分batch\n",
    "# neg = label_batch - pred\n",
    "# neg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(neg)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_abs = np.abs(neg)\n",
    "# neg_abs.mean(axis=0)#所有x 所有y個別平均  neg.mean(axis=0)#所有x 所有y個別平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ED 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred = neg_abs.mean(axis=0)\n",
    "# ed_metric_2d([0,0], [neg_abs.mean(axis=0)]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merg Toe/Heel model and predict the Test data at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TEST DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 'test_submission.csv'\n",
    "df_ts = pd.read_csv(ts)\n",
    "df_ts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe\n",
    "list_ds_test = tf.data.Dataset.from_tensor_slices(df_ts['images'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_ds_test)#.shape() #take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check The type specification of an element of this dataset.\n",
    "list_ds_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds_test.take(5):\n",
    "    print(f'take test sample: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DS: Process TEST path to image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST-DS: re-used from train/val-ds\n",
    "\n",
    "im_test = 'test_images/'\n",
    "\n",
    "'''\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    boolen = parts[-2] == class_names\n",
    "    #one_hot_num = np.array(boolen, dtype=np.int) not works should use tf.x repalced.\n",
    "    one_hot_num = tf.dtypes.cast(boolen, tf.int64)\n",
    "    one_num = tf.argmax(one_hot_num)\n",
    "    print('one_num:', one_num)\n",
    "    # Integer encode the label\n",
    "    return one_num\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])# augment 已經resize過一次了 但這邊不先做會比較慢\n",
    "    return tf.cast(tf.image.resize(img, [img_height, img_width]), tf.uint8)# 避免float over at augment\n",
    "'''\n",
    "\n",
    "#\n",
    "# map list to ds, Toe part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_toe_test(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y1=y_offset_toe;    x1=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_toe_test(file_name):\n",
    "    file_path = im_test + file_name\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_toe_test(img)\n",
    "    return img, file_name\n",
    "\n",
    "#\n",
    "# map list to ds, Heel part.\n",
    "#\n",
    "\n",
    "def decode_crop_png_heel_test(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    # crop the toe from top-left corner [image, offset_height y1, offset_width x1, target_height, target_width]\n",
    "    y2=y_offset_heel;    x2=0;    h=img_height;    w=img_width # not the pp location\n",
    "    img = tf.image.crop_to_bounding_box(img, int(y2), int(x2), h, w)\n",
    "    #img = tf.image.crop_to_bounding_box(img, int(y1), int(x1), int(y2)-int(y1), int(x2)-int(x1))\n",
    "    # resize the image to the desired size\n",
    "    return img\n",
    "\n",
    "def process_path_heel_test(file_name):\n",
    "    file_path = im_test + file_name\n",
    "    #label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)#can read the byte string paths b'image_0001.png'\n",
    "    img = decode_crop_png_heel_test(img)\n",
    "    return img, file_name\n",
    "\n",
    "\n",
    "#\n",
    "# test how to put parameters to map\n",
    "#\n",
    "\n",
    "def t_ds_map(file_path,x1,y1,x2,y2):\n",
    "#     img = get_img('train/images/' + str(file_path))\n",
    "#     print(file_path)\n",
    "    return file_path,x1,y1,x2,y2 #img, [x1,y1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Toe ds\n",
    "test_ds_map_toe = list_ds_test.map(process_path_toe_test, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# TEST Heel ds\n",
    "test_ds_map_heel = list_ds_test.map(process_path_heel_test, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, file_name in test_ds_map_toe.take(5):\n",
    "    print(f'take sample: {img.shape} {file_name}')\n",
    "    \n",
    "# print('f', f.dtype)\n",
    "# print('xy', xy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare TEST_ds_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance_cache_test(ds, cache=True):\n",
    "\n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "        print(\"Check cache in memory:Y\", cache)\n",
    "    else:\n",
    "        print(\"Check cache in memory:N\", cache)\n",
    "        \n",
    "#     if augment:\n",
    "# #         ds = ds.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(AA, num_parallel_calls=AUTOTUNE)\n",
    "# #         ds = ds.map(RA, num_parallel_calls=AUTOTUNE)\n",
    "#         print(\"Check augment :Y\", augment)\n",
    "#     else:\n",
    "#         print(\"Check augment :N\", augment)\n",
    "    \n",
    "#     #ds = ds.repeat()#TODO:2020-12-14: test\n",
    "#     ds = ds.shuffle(buffer_size=MULTI_BATCH_SIZE*2) # (buffer_size=MULTI_BATCH_SIZE*5) 6sec,buffer_size=1000 take few sec. or buffer_size=image_count <- take too long # each take ds take 30~45 sec, TODO!!\n",
    "#     ds = ds.shuffle(len(list_ds), reshuffle_each_iteration=False) #todo: move to ds_pre. see https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
    "    ds = ds.batch(1000)# 1k for foot test images #MULTI_BATCH_SIZE for multi-GPUs\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) #buffer_size=AUTOTUNE seem no speed improve\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare the ds properties (cache, augment, bs, shuffle, prefetch, etc.) for better performance.\n",
    "\"\"\"\n",
    "# TEST Toe ds_pre\n",
    "test_ds_pre_toe = configure_for_performance_cache_test(test_ds_map_toe)\n",
    "\n",
    "# TEST Heel ds_pre\n",
    "test_ds_pre_heel = configure_for_performance_cache_test(test_ds_map_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best-K-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if K-models are in last time frame\n",
    "# best_model_name = get_best_model_name(th, K=str(k))\n",
    "\n",
    "predictions_toe = []\n",
    "predictions_heel = []\n",
    "\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "    best_model_toe_name = get_best_model_name('toe', K=str(k))\n",
    "    best_model_heel_name = get_best_model_name('heel', K=str(k))\n",
    "\n",
    "# # if models are in last time frame\n",
    "# best_model_toe_name = get_best_model_name('toe')\n",
    "# best_model_heel_name = get_best_model_name('heel')\n",
    "\n",
    "# # if toe/heel are in different time frame\n",
    "# best_model_toe_name = '20210118-212454/toe_EfficientNetB0_bs64_w120_best_val_loss.h5'#6.3318 @e393\n",
    "# best_model_heel_name = '20210122-084854/heel_EfficientNetB0_bs64_w120_best_val_loss.h5'#3.27979@152\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(best_model_toe_name)\n",
    "    print(best_model_heel_name)\n",
    "    # log_dir_name + '/' + 'leaf-2020-12-01-EfficientNetB7_top-layer50_lr_lrfn_val-acc.8352_wh512_e37.h5'\n",
    "\n",
    "    best_model_toe = tf.keras.models.load_model(best_model_toe_name,compile=False)\n",
    "    best_model_heel = tf.keras.models.load_model(best_model_heel_name,compile=False)\n",
    "    \n",
    "    best_model_toe.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "                loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "                #metrics=['mae', 'accuracy'])\n",
    "    best_model_heel.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "                loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "                #metrics=['mae', 'accuracy'])\n",
    "        \n",
    "        \n",
    "    pred_toe = best_model_toe.predict(test_ds_pre_toe)\n",
    "    pred_toe[:,1] = pred_toe[:,1] + y_offset_toe\n",
    "    predictions_toe.append(pred_toe)\n",
    "    \n",
    "    pred_heel = best_model_heel.predict(test_ds_pre_heel)\n",
    "    pred_heel[:,1] = pred_heel[:,1] + y_offset_heel\n",
    "    predictions_heel.append(pred_heel)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_toe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we got the k-pred as k models.\n",
    "for i, _ in enumerate(predictions_toe):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(predictions_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_toe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_toe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_heel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_heel[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean the k-predictions\n",
    "k_predictions_toe = np.mean(predictions_toe, axis=0)\n",
    "k_predictions_toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(k_predictions_toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean the k-predictions\n",
    "k_predictions_heel = np.mean(predictions_heel, axis=0)\n",
    "k_predictions_heel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge toe/hell pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_th = np.append(k_predictions_toe, k_predictions_heel, axis=1)#左右接\n",
    "predictions_th.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name = np.expand_dims(df_ts['images'], axis=1)\n",
    "images_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_merge = np.append(images_name, predictions_th, axis=1)#左右接\n",
    "predictions_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(predictions_merge)\n",
    "df_submission.columns = ['images','x1','y1','x2','y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submi_name = CSVNAME + '.' + log_dir_name +'.csv'\n",
    "\n",
    "df_submission.to_csv(submi_name, index=False)\n",
    "print('Save {} as submission CSV.'.format(submi_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ED sum\n",
    "def get_valloss(his_v_l):  \n",
    "    return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "t_vl = []\n",
    "h_vl = []\n",
    "for k in range(KFlodNum):\n",
    "    print(f'K:{k}')\n",
    "    t_v, _ = get_valloss(history_toe_finetune[k].history['val_loss'])\n",
    "    h_v, _ = get_valloss(history_heel_finetune[k].history['val_loss'])\n",
    "    \n",
    "    t_vl.append(t_v)\n",
    "    h_vl.append(h_v)\n",
    "\n",
    "t_vl = np.mean(t_vl, axis=0)\n",
    "h_vl = np.mean(h_vl, axis=0)\n",
    "print(f'{round(t_vl,5)} + {round(h_vl,5)} = {round(t_vl + h_vl,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K134520210224-114845.csv\n",
    "# 5.63922 + 3.34466 = 8.98389 LB:8.4890610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_timer.toc() #Time elapsed since t.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model separately afterwards. to load model with custom loss function\n",
    "\n",
    "* https://github.com/tensorflow/tensorflow/issues/32348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_toe.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "# best_model_heel.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=ed_metric_2d_mean)#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "\n",
    "# best_model_toe.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=tf.keras.losses.MeanSquaredError())#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "# best_model_heel.compile(optimizer = tf.keras.optimizers.Adam(),#RMSprop , Adam\n",
    "#                 loss=tf.keras.losses.MeanSquaredError())#, ed_loss ed_metric_2d ed_metric_2d_mean            \n",
    "#                 #metrics=['mae', 'accuracy'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # inference all test_ds once\n",
    "# predictions_toe = best_model_toe.predict(test_ds_pre_toe)\n",
    "# predictions_toe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_toe[:,1] = predictions_toe[:,1] + y_offset_toe\n",
    "\n",
    "# # for [0,1]\n",
    "# # predictions_toe[:,0] = predictions_toe[:,0]*120\n",
    "# # predictions_toe[:,1] = predictions_toe[:,1]*120 + y_offset_toe\n",
    "\n",
    "# # # for [-1,1]\n",
    "# # # for re-scale back xy \n",
    "# # # return img, [(x1-60)/60,((y1-y_offset_toe)-60)/60]#normalized [-1,1] \n",
    "# # # return img, [(x2-60)/60,((y2-y_offset_heel)-60)/60]#normalized [-1,1] \n",
    "# # predictions_toe[:,0] = (predictions_toe[:,0]*60)+60\n",
    "# # predictions_toe[:,1] = (predictions_toe[:,1]*60)+60 + y_offset_toe\n",
    "\n",
    "# predictions_toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # inference all test_ds once\n",
    "# predictions_heel = best_model_heel.predict(test_ds_pre_heel)\n",
    "# predictions_heel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Heel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_heel[:,1] = predictions_heel[:,1] + y_offset_heel\n",
    "\n",
    "# # for [0,1]\n",
    "# # predictions_heel[:,0] = predictions_heel[:,0]*120\n",
    "# # predictions_heel[:,1] = predictions_heel[:,1]*120 + y_offset_heel\n",
    "\n",
    "# # # for [-1,1]\n",
    "# # predictions_heel[:,0] = (predictions_heel[:,0]*60)+60\n",
    "# # predictions_heel[:,1] = (predictions_heel[:,1]*60)+60 + y_offset_heel\n",
    "\n",
    "# predictions_heel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge toe/hell pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_th = np.append(predictions_toe, predictions_heel, axis=1)#左右接\n",
    "# predictions_th.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_name = np.expand_dims(df_ts['images'], axis=1)\n",
    "# images_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_merge = np.append(images_name, predictions_th, axis=1)#左右接\n",
    "# predictions_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame(predictions_merge)\n",
    "# df_submission.columns = ['images','x1','y1','x2','y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submi_name = '0000_ft_' + log_dir_name +'.csv'\n",
    "# # submi_name = 'Bth_clr3_2690_XYnorm[0-1]_' + log_dir_name +'.csv'\n",
    "# df_submission.to_csv(submi_name, index=False)\n",
    "# print('Save {} as submission CSV.'.format(submi_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bth_clr3_2690_ed_findtune_20210202-141718.csv\n",
    "\n",
    "#toe.9.9/heel.4.4 109 trainable LB:9.3411759 比heel保持top-20略高0.04 (9.3084957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ED sum\n",
    "# def get_valloss(his_v_l):  \n",
    "#     return np.min(his_v_l), np.argmin(his_v_l)\n",
    "\n",
    "# t_vl, _ = get_valloss(history_toe_finetune.history['val_loss'])\n",
    "# h_vl, _ = get_valloss(history_heel_finetune.history['val_loss'])\n",
    "\n",
    "# print(f'{round(t_vl,5)} + {round(h_vl,5)} = {round(t_vl + h_vl,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# best_model_name = './cop_' + model_name + '_bs' + str(BATCH_SIZE) + '_w' + str(img_width) + '_e' + str(ep_num) + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_.h5'\n",
    "# # model.save(best_model_name)\n",
    "# print(\"Save model: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "multi output model:\n",
    "https://navoshta.com/end-to-end-deep-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
